{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     file  \\\n",
      "0       server/src/main/java/org/elasticsearch/cluster...   \n",
      "1       server/src/main/java/org/elasticsearch/cluster...   \n",
      "2       server/src/main/java/org/elasticsearch/cluster...   \n",
      "3       server/src/main/java/org/elasticsearch/cluster...   \n",
      "4       server/src/main/java/org/elasticsearch/cluster...   \n",
      "...                                                   ...   \n",
      "417737  plugins/analysis-stempel/src/main/java/org/ela...   \n",
      "417738  plugins/analysis-stempel/src/test/java/org/ela...   \n",
      "417739  plugins/analysis-stempel/src/test/java/org/ela...   \n",
      "417740  plugins/analysis-smartcn/src/main/java/org/ela...   \n",
      "417741  plugins/analysis-kuromoji/src/main/java/org/el...   \n",
      "\n",
      "                                                    class        type  cbo  \\\n",
      "0       org.elasticsearch.cluster.coordination.Followe...   anonymous    3   \n",
      "1       org.elasticsearch.cluster.coordination.Followe...       class   21   \n",
      "2       org.elasticsearch.cluster.coordination.Followe...  innerclass    5   \n",
      "3       org.elasticsearch.cluster.coordination.Followe...   anonymous    7   \n",
      "4       org.elasticsearch.cluster.coordination.Followe...   anonymous    3   \n",
      "...                                                   ...         ...  ...   \n",
      "417737  org.elasticsearch.plugin.analysis.stempel.Anal...       class    4   \n",
      "417738  org.elasticsearch.index.analysis.PolishAnalysi...       class    8   \n",
      "417739  org.elasticsearch.index.analysis.SimplePolishT...       class   12   \n",
      "417740  org.elasticsearch.plugin.analysis.smartcn.Anal...       class    4   \n",
      "417741  org.elasticsearch.plugin.analysis.kuromoji.Ana...       class    4   \n",
      "\n",
      "        cboModified  fanin  fanout  wmc  dit  noc  ...  assignmentsQty  \\\n",
      "0                 3      0       3    1    1    0  ...               0   \n",
      "1                24      3      21   20    2    0  ...              23   \n",
      "2                 5      0       5    9    1    0  ...               2   \n",
      "3                 7      0       7    9    1    0  ...               5   \n",
      "4                 3      0       3    6    1    0  ...               0   \n",
      "...             ...    ...     ...  ...  ...  ...  ...             ...   \n",
      "417737            7      3       4    2    2    0  ...               0   \n",
      "417738            8      0       8    1    2    0  ...               3   \n",
      "417739           13      1      12    4    2    0  ...              11   \n",
      "417740            6      2       4    3    2    0  ...               2   \n",
      "417741            6      2       4    4    2    0  ...               2   \n",
      "\n",
      "        mathOperationsQty  variablesQty  maxNestedBlocksQty  \\\n",
      "0                       0             0                   0   \n",
      "1                       4            28                   3   \n",
      "2                       2             4                   1   \n",
      "3                       2             1                   1   \n",
      "4                       1             0                   2   \n",
      "...                   ...           ...                 ...   \n",
      "417737                  0             0                   0   \n",
      "417738                  0             3                   0   \n",
      "417739                  0            11                   1   \n",
      "417740                  0             2                   0   \n",
      "417741                  0             2                   0   \n",
      "\n",
      "        anonymousClassesQty  innerClassesQty  lambdasQty  uniqueWordsQty  \\\n",
      "0                         0                0           0               7   \n",
      "1                         1                2           4             189   \n",
      "2                         3                0           0              38   \n",
      "3                         0                0           4              42   \n",
      "4                         0                0           0              34   \n",
      "...                     ...              ...         ...             ...   \n",
      "417737                    0                0           0              10   \n",
      "417738                    0                0           0              23   \n",
      "417739                    0                0           0              45   \n",
      "417740                    0                0           0              14   \n",
      "417741                    0                0           0              13   \n",
      "\n",
      "        modifiers  logStatementsQty  \n",
      "0              -1                 0  \n",
      "1               1                 3  \n",
      "2               2                 2  \n",
      "3              -1                 7  \n",
      "4              -1                 4  \n",
      "...           ...               ...  \n",
      "417737          1                 0  \n",
      "417738          1                 0  \n",
      "417739          1                 0  \n",
      "417740          1                 0  \n",
      "417741          1                 0  \n",
      "\n",
      "[417742 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#load ../ck_metrics_output/class.csv as a dataframe\n",
    "df1 = pd.read_csv('../ck_metrics_output/class.csv')\n",
    "\n",
    "# load ../dataset/java/elasticsearch/dataset.csv\n",
    "df2 = pd.read_csv('../dataset/java/elasticsearch/dataset.csv')\n",
    "\n",
    "# match file names in both dfs. But first,\n",
    "# remove the path up until elasticsearch folder in df1['file']\n",
    "# and split the df1['fileschanged'] by 'CAS_DELIMITER'. There might be preceding and trailing commas, so remove them\n",
    "# then match every file in that splitted array with df2['file']\n",
    "# and create a new df with the matched files\n",
    "\n",
    "# Remove the path up until elasticsearch folder in df1['file']\n",
    "df1['file'] = df1['file'].apply(lambda x: os.path.relpath(x, start='C:\\\\Coding\\\\JIT-SDP\\\\repositories\\\\elasticsearch'))\n",
    "# Replace '\\' with '/' in df1['file']\n",
    "df1['file'] = df1['file'].apply(lambda x: x.replace('\\\\', '/'))\n",
    "\n",
    "# Save df1 file column to a new file\n",
    "df1[['file']].to_csv('df1_files.csv', index=False)\n",
    "\n",
    "# Split the df1['fileschanged'] by 'CAS_DELIMITER' and remove preceding and trailing commas\n",
    "df2['fileschanged'] = df2['fileschanged'].fillna('').apply(lambda x: [f.strip(',') for f in x.split('CAS_DELIMITER') if f.strip(',')])\n",
    "\n",
    "# Save df2 fileschanged column to a new file\n",
    "df2[['fileschanged']].to_csv('df2_fileschanged.csv', index=False)\n",
    "\n",
    "# Match every file in that splitted array with df2['file']\n",
    "matched_files = df2.explode('fileschanged').merge(df1, left_on='fileschanged', right_on='file')\n",
    "\n",
    "# Create a new dataframe with the matched files\n",
    "matched_df = matched_files[['file', 'class', 'type', 'cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*', 'tcc', 'lcc', 'totalMethodsQty', 'staticMethodsQty', 'publicMethodsQty', 'privateMethodsQty', 'protectedMethodsQty', 'defaultMethodsQty', 'visibleMethodsQty', 'abstractMethodsQty', 'finalMethodsQty', 'synchronizedMethodsQty', 'totalFieldsQty', 'staticFieldsQty', 'publicFieldsQty', 'privateFieldsQty', 'protectedFieldsQty', 'defaultFieldsQty', 'finalFieldsQty', 'synchronizedFieldsQty', 'nosi', 'loc', 'returnQty', 'loopQty', 'comparisonsQty', 'tryCatchQty', 'parenthesizedExpsQty', 'stringLiteralsQty', 'numbersQty', 'assignmentsQty', 'mathOperationsQty', 'variablesQty', 'maxNestedBlocksQty', 'anonymousClassesQty', 'innerClassesQty', 'lambdasQty', 'uniqueWordsQty', 'modifiers', 'logStatementsQty']]\n",
    "\n",
    "print(matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every file in df1['file'], get its metrics from df2 from matching files.\n",
    "# if there are multiple matching files, get the average value of the metrics\n",
    "# Merge those into a new dataframe and save it as a csv file\n",
    "# Group by 'file' and calculate the mean of the metrics\n",
    "metrics_columns = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*', 'tcc', 'lcc', \n",
    "                   'totalMethodsQty', 'staticMethodsQty', 'publicMethodsQty', 'privateMethodsQty', 'protectedMethodsQty', \n",
    "                   'defaultMethodsQty', 'visibleMethodsQty', 'abstractMethodsQty', 'finalMethodsQty', 'synchronizedMethodsQty', \n",
    "                   'totalFieldsQty', 'staticFieldsQty', 'publicFieldsQty', 'privateFieldsQty', 'protectedFieldsQty', \n",
    "                   'defaultFieldsQty', 'finalFieldsQty', 'synchronizedFieldsQty', 'nosi', 'loc', 'returnQty', 'loopQty', \n",
    "                   'comparisonsQty', 'tryCatchQty', 'parenthesizedExpsQty', 'stringLiteralsQty', 'numbersQty', 'assignmentsQty', \n",
    "                   'mathOperationsQty', 'variablesQty', 'maxNestedBlocksQty', 'anonymousClassesQty', 'innerClassesQty', \n",
    "                   'lambdasQty', 'uniqueWordsQty', 'modifiers', 'logStatementsQty']\n",
    "\n",
    "# Merge df1 and df2 on 'file'. Have all attributes from both tables\n",
    "merged_df = df1.merge(df2.explode('fileschanged'), left_on='file', right_on='fileschanged', how='left')\n",
    "\n",
    "# Save the merged df to a csv file\n",
    "merged_df.to_csv('merged_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
