{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ROOT_DIR = Path(\"..\")\n",
    "DATASET_FOLDER = ROOT_DIR / 'dataset' / 'java' / 'elasticsearch'\n",
    "COMMITS_FILE = DATASET_FOLDER / 'commit_history.txt'\n",
    "COMMIT_INFORMATION_FILE = DATASET_FOLDER / 'dataset.csv'\n",
    "CK_METRICS_FOLDER = Path(\"D:\") / 'CK'\n",
    "\n",
    "# used in the commit information file\n",
    "CAS_DELIMITER = 'CAS_DELIMITER'\n",
    "\n",
    "# Metrics to calculate deltas for\n",
    "DELTA_METRIC_COLUMNS = [\"cbo\", \"cboModified\", \"fanin\", \"fanout\", \"wmc\", \n",
    "    \"dit\", \"noc\", \"rfc\", \"lcom\", \"lcom*\", \"tcc\", \"lcc\", \n",
    "    \"totalMethodsQty\", \"staticMethodsQty\", \"publicMethodsQty\", \"privateMethodsQty\", \n",
    "    \"protectedMethodsQty\", \"defaultMethodsQty\", \"visibleMethodsQty\", \n",
    "    \"abstractMethodsQty\", \"finalMethodsQty\", \"synchronizedMethodsQty\", \n",
    "    \"totalFieldsQty\", \"staticFieldsQty\", \"publicFieldsQty\", \"privateFieldsQty\", \n",
    "    \"protectedFieldsQty\", \"defaultFieldsQty\", \"finalFieldsQty\", \"synchronizedFieldsQty\", \n",
    "    \"nosi\", \"loc\", \"returnQty\", \"loopQty\", \"comparisonsQty\", \"tryCatchQty\", \n",
    "    \"parenthesizedExpsQty\", \"stringLiteralsQty\", \"numbersQty\", \n",
    "    \"assignmentsQty\", \"mathOperationsQty\", \"variablesQty\", \"maxNestedBlocksQty\", \n",
    "    \"anonymousClassesQty\", \"innerClassesQty\", \"lambdasQty\"]\n",
    "\n",
    "CURRENT_STATE_ONLY_COLUMNS = [\n",
    "    \"uniqueWordsQty\", \n",
    "    \"modifiers\", \n",
    "    \"logStatementsQty\"\n",
    "]\n",
    "\n",
    "COMMIT_INFO_COLUMNS = [\n",
    "    \"fix\",               # Boolean\n",
    "    \"classification\",    # Categorical\n",
    "    \"linked\",            # Boolean\n",
    "    \"contains_bug\",      # Boolean\n",
    "    \"entrophy\",          # Numeric\n",
    "    \"la\",                # Lines Added\n",
    "    \"ld\",                # Lines Deleted\n",
    "    \"fileschanged\",      # Count of files changed\n",
    "    \"ndev\",              # Number of developers\n",
    "    \"age\",               # Average file age\n",
    "    \"exp\",               # Developer experience\n",
    "    \"rexp\",              # Recent experience\n",
    "    \"sexp\",              # Subsystem experience\n",
    "    \"glm_probability\"    # Numeric\n",
    "]\n",
    "\n",
    "# Updated COMMIT_INFO_EXTENDED_COLUMNS with vectorized lambdas\n",
    "COMMIT_INFO_EXTENDED_COLUMNS = {\n",
    "    \"time_of_day\": lambda df: df[\"author_date_unix_timestamp\"].dt.hour,\n",
    "    \"day_of_week\": lambda df: df[\"author_date_unix_timestamp\"].dt.dayofweek,\n",
    "    \"is_weekend\": lambda df: df[\"author_date_unix_timestamp\"].dt.dayofweek > 4,\n",
    "    \"net_lines_changed\": lambda df: df[\"la\"] - df[\"ld\"],\n",
    "    \"absolute_lines_changed\": lambda df: abs(df[\"la\"] + df[\"ld\"]),\n",
    "    \"lines_per_file\": lambda df: (df[\"la\"] + df[\"ld\"]) / (df[\"fileschanged\"].str.count(\",\") + 1),\n",
    "    \"author_experience\": lambda df: df[\"exp\"],\n",
    "    \"author_ownership\": lambda df: df[\"ndev\"],\n",
    "    \"changed_file_count\": lambda df: df[\"fileschanged\"].str.count(\",\") + 1,\n",
    "    \"entropy_bucket\": lambda df: pd.cut(\n",
    "        df[\"entrophy\"], bins=3, labels=[\"low\", \"medium\", \"high\"]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commit_parent_hash(commit_hash: str, commits_df: pd.DataFrame) -> str:\n",
    "\n",
    "    # find the commit index in the dataframe and return previous hash\n",
    "    commit_index = commits_df[commits_df['hash'] == commit_hash].index[0]\n",
    "    # retunr previous hash\n",
    "    parent_hash = commits_df.iloc[commit_index + 1]['hash']\n",
    "\n",
    "    return parent_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute extended columns dynamically\n",
    "def precompute_extended_columns(commit_info_df, extended_columns):\n",
    "    for column, func in extended_columns.items():\n",
    "        if callable(func):\n",
    "            # Apply the function across the DataFrame without axis=1\n",
    "            commit_info_df[column] = func(commit_info_df)\n",
    "        else:\n",
    "            raise ValueError(f\"Function for column '{column}' must be callable\")\n",
    "    return commit_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e0f4b01fb8655c82e1b62dcb07973016ed411297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1141edee4797f772a542528a296df2d802b50122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31578be7502c267e11bed31af064b857bbd2d490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e5b94ae033c10921a4a3ebb7274d89420d11d6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97bc2919ffb5d9e90f809a18233c49a52cf58faa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82183</th>\n",
       "      <td>bd2b0a632bfc5aabb408e7f47cfaa52a7d1b2b50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82184</th>\n",
       "      <td>78c220589e4e317523268be8401647014fbe95b4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82185</th>\n",
       "      <td>7004a9e5bae12864d2c1e05e3233183cbf2006c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82186</th>\n",
       "      <td>b3337c312765e51cec7bde5883bbc0a08f56fb65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82187</th>\n",
       "      <td>ec72ca8b7a115f9b2eea3c76c518062b99a1d015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82188 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           hash\n",
       "0      e0f4b01fb8655c82e1b62dcb07973016ed411297\n",
       "1      1141edee4797f772a542528a296df2d802b50122\n",
       "2      31578be7502c267e11bed31af064b857bbd2d490\n",
       "3      4e5b94ae033c10921a4a3ebb7274d89420d11d6b\n",
       "4      97bc2919ffb5d9e90f809a18233c49a52cf58faa\n",
       "...                                         ...\n",
       "82183  bd2b0a632bfc5aabb408e7f47cfaa52a7d1b2b50\n",
       "82184  78c220589e4e317523268be8401647014fbe95b4\n",
       "82185  7004a9e5bae12864d2c1e05e3233183cbf2006c2\n",
       "82186  b3337c312765e51cec7bde5883bbc0a08f56fb65\n",
       "82187  ec72ca8b7a115f9b2eea3c76c518062b99a1d015\n",
       "\n",
       "[82188 rows x 1 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read commit history\n",
    "commits = pd.read_csv(COMMITS_FILE, header=None, names=['hash'])\n",
    "commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_hash</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_date_unix_timestamp</th>\n",
       "      <th>author_email</th>\n",
       "      <th>author_date</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>fix</th>\n",
       "      <th>classification</th>\n",
       "      <th>linked</th>\n",
       "      <th>contains_bug</th>\n",
       "      <th>...</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>net_lines_changed</th>\n",
       "      <th>absolute_lines_changed</th>\n",
       "      <th>lines_per_file</th>\n",
       "      <th>author_experience</th>\n",
       "      <th>author_ownership</th>\n",
       "      <th>changed_file_count</th>\n",
       "      <th>entropy_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b868b0e11f4a59d608523c57d1a62b870ac8e0e</td>\n",
       "      <td>Niels Bauman</td>\n",
       "      <td>2024-12-09 16:57:40</td>\n",
       "      <td>33722607+nielsbauman@users.noreply.github.com</td>\n",
       "      <td>Mon Dec 9 17:57:40 2024 +0100</td>\n",
       "      <td>Fix enrich cache size setting name (#117575)Th...</td>\n",
       "      <td>True</td>\n",
       "      <td>Corrective</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>120.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>392.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e859d9301ffe736548dfc2b6e72807a7f9006ff</td>\n",
       "      <td>Benjamin Trent</td>\n",
       "      <td>2024-12-09 16:06:27</td>\n",
       "      <td>ben.w.trent@gmail.com</td>\n",
       "      <td>Mon Dec 9 11:06:27 2024 -0500</td>\n",
       "      <td>Even better(er) binary quantization (#117994)T...</td>\n",
       "      <td>False</td>\n",
       "      <td>Feature Addition</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>3638.0</td>\n",
       "      <td>113.687500</td>\n",
       "      <td>8249.5</td>\n",
       "      <td>632.0</td>\n",
       "      <td>32</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0586cbfb34c7201a996578db60d12fea8594261c</td>\n",
       "      <td>David Turner</td>\n",
       "      <td>2024-12-09 15:46:22</td>\n",
       "      <td>david.turner@elastic.co</td>\n",
       "      <td>Mon Dec 9 15:46:22 2024 +0000</td>\n",
       "      <td>Remove unused `BlobStore#deleteBlobsIgnoringIf...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>7.238095</td>\n",
       "      <td>15618.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>21</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22a392f1b69224aac3894dd6a05b892ccbb6a75d</td>\n",
       "      <td>Ryan Ernst</td>\n",
       "      <td>2024-12-09 15:33:11</td>\n",
       "      <td>ryan@iernst.net</td>\n",
       "      <td>Mon Dec 9 07:33:11 2024 -0800</td>\n",
       "      <td>Remove client.type setting (#118192)The client...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>43014.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ecf981f24ca5d480466a4fcc669aeb52d063657</td>\n",
       "      <td>David Kyle</td>\n",
       "      <td>2024-12-09 15:22:48</td>\n",
       "      <td>david.kyle@elastic.co</td>\n",
       "      <td>Mon Dec 9 15:22:48 2024 +0000</td>\n",
       "      <td>[ML] Refactor the Chunker classes to return of...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>27.857143</td>\n",
       "      <td>5870.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>7</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45602</th>\n",
       "      <td>ade36f026b0a676cc879992636856cd5f69430c1</td>\n",
       "      <td>kimchy</td>\n",
       "      <td>2010-02-11 20:34:11</td>\n",
       "      <td>kimchy@gmail.com</td>\n",
       "      <td>Thu Feb 11 22:34:11 2010 +0200</td>\n",
       "      <td>TransportClient to automatically retry another...</td>\n",
       "      <td>True</td>\n",
       "      <td>Corrective</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>269.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>110.600000</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45603</th>\n",
       "      <td>847db717c66509a817e1b965226ee1e44c08918d</td>\n",
       "      <td>kimchy</td>\n",
       "      <td>2010-02-11 17:29:25</td>\n",
       "      <td>kimchy@gmail.com</td>\n",
       "      <td>Thu Feb 11 19:29:25 2010 +0200</td>\n",
       "      <td>Transport: Support local (JVM level) transport...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>661.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>57.083333</td>\n",
       "      <td>1372.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45604</th>\n",
       "      <td>b61964a2b8a4f6465928efcb5b1b434dbbb6b1a5</td>\n",
       "      <td>kimchy</td>\n",
       "      <td>2010-02-10 22:12:32</td>\n",
       "      <td>kimchy@gmail.com</td>\n",
       "      <td>Thu Feb 11 00:12:32 2010 +0200</td>\n",
       "      <td>Discovery: Support local (JVM level) discovery...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>381.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>48.875000</td>\n",
       "      <td>1362.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45605</th>\n",
       "      <td>bd2b0a632bfc5aabb408e7f47cfaa52a7d1b2b50</td>\n",
       "      <td>kimchy</td>\n",
       "      <td>2010-02-09 20:18:46</td>\n",
       "      <td>kimchy@gmail.com</td>\n",
       "      <td>Tue Feb 9 22:18:46 2010 +0200</td>\n",
       "      <td>Support terms filter, closes #1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>40.833333</td>\n",
       "      <td>1355.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45606</th>\n",
       "      <td>b3337c312765e51cec7bde5883bbc0a08f56fb65</td>\n",
       "      <td>kimchy</td>\n",
       "      <td>2010-02-08 13:30:06</td>\n",
       "      <td>kimchy@gmail.com</td>\n",
       "      <td>Mon Feb 8 15:30:06 2010 +0200</td>\n",
       "      <td>initial commit</td>\n",
       "      <td>False</td>\n",
       "      <td>Feature Addition</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>182199.0</td>\n",
       "      <td>182199.0</td>\n",
       "      <td>134.962222</td>\n",
       "      <td>675.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1350</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45607 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    commit_hash     author_name  \\\n",
       "0      4b868b0e11f4a59d608523c57d1a62b870ac8e0e    Niels Bauman   \n",
       "1      5e859d9301ffe736548dfc2b6e72807a7f9006ff  Benjamin Trent   \n",
       "2      0586cbfb34c7201a996578db60d12fea8594261c    David Turner   \n",
       "3      22a392f1b69224aac3894dd6a05b892ccbb6a75d      Ryan Ernst   \n",
       "4      2ecf981f24ca5d480466a4fcc669aeb52d063657      David Kyle   \n",
       "...                                         ...             ...   \n",
       "45602  ade36f026b0a676cc879992636856cd5f69430c1          kimchy   \n",
       "45603  847db717c66509a817e1b965226ee1e44c08918d          kimchy   \n",
       "45604  b61964a2b8a4f6465928efcb5b1b434dbbb6b1a5          kimchy   \n",
       "45605  bd2b0a632bfc5aabb408e7f47cfaa52a7d1b2b50          kimchy   \n",
       "45606  b3337c312765e51cec7bde5883bbc0a08f56fb65          kimchy   \n",
       "\n",
       "      author_date_unix_timestamp  \\\n",
       "0            2024-12-09 16:57:40   \n",
       "1            2024-12-09 16:06:27   \n",
       "2            2024-12-09 15:46:22   \n",
       "3            2024-12-09 15:33:11   \n",
       "4            2024-12-09 15:22:48   \n",
       "...                          ...   \n",
       "45602        2010-02-11 20:34:11   \n",
       "45603        2010-02-11 17:29:25   \n",
       "45604        2010-02-10 22:12:32   \n",
       "45605        2010-02-09 20:18:46   \n",
       "45606        2010-02-08 13:30:06   \n",
       "\n",
       "                                        author_email  \\\n",
       "0      33722607+nielsbauman@users.noreply.github.com   \n",
       "1                              ben.w.trent@gmail.com   \n",
       "2                            david.turner@elastic.co   \n",
       "3                                    ryan@iernst.net   \n",
       "4                              david.kyle@elastic.co   \n",
       "...                                              ...   \n",
       "45602                               kimchy@gmail.com   \n",
       "45603                               kimchy@gmail.com   \n",
       "45604                               kimchy@gmail.com   \n",
       "45605                               kimchy@gmail.com   \n",
       "45606                               kimchy@gmail.com   \n",
       "\n",
       "                          author_date  \\\n",
       "0       Mon Dec 9 17:57:40 2024 +0100   \n",
       "1       Mon Dec 9 11:06:27 2024 -0500   \n",
       "2       Mon Dec 9 15:46:22 2024 +0000   \n",
       "3       Mon Dec 9 07:33:11 2024 -0800   \n",
       "4       Mon Dec 9 15:22:48 2024 +0000   \n",
       "...                               ...   \n",
       "45602  Thu Feb 11 22:34:11 2010 +0200   \n",
       "45603  Thu Feb 11 19:29:25 2010 +0200   \n",
       "45604  Thu Feb 11 00:12:32 2010 +0200   \n",
       "45605   Tue Feb 9 22:18:46 2010 +0200   \n",
       "45606   Mon Feb 8 15:30:06 2010 +0200   \n",
       "\n",
       "                                          commit_message    fix  \\\n",
       "0      Fix enrich cache size setting name (#117575)Th...   True   \n",
       "1      Even better(er) binary quantization (#117994)T...  False   \n",
       "2      Remove unused `BlobStore#deleteBlobsIgnoringIf...  False   \n",
       "3      Remove client.type setting (#118192)The client...  False   \n",
       "4      [ML] Refactor the Chunker classes to return of...  False   \n",
       "...                                                  ...    ...   \n",
       "45602  TransportClient to automatically retry another...   True   \n",
       "45603  Transport: Support local (JVM level) transport...  False   \n",
       "45604  Discovery: Support local (JVM level) discovery...  False   \n",
       "45605                    Support terms filter, closes #1  False   \n",
       "45606                                     initial commit  False   \n",
       "\n",
       "         classification  linked  contains_bug  ...  time_of_day  day_of_week  \\\n",
       "0            Corrective    True         False  ...           16            0   \n",
       "1      Feature Addition   False         False  ...           16            0   \n",
       "2                   NaN   False         False  ...           15            0   \n",
       "3                   NaN   False         False  ...           15            0   \n",
       "4                   NaN   False         False  ...           15            0   \n",
       "...                 ...     ...           ...  ...          ...          ...   \n",
       "45602        Corrective    True         False  ...           20            3   \n",
       "45603               NaN   False         False  ...           17            3   \n",
       "45604               NaN   False         False  ...           22            2   \n",
       "45605               NaN   False         False  ...           20            1   \n",
       "45606  Feature Addition   False          True  ...           13            0   \n",
       "\n",
       "       is_weekend  net_lines_changed  absolute_lines_changed  lines_per_file  \\\n",
       "0           False              120.0                   126.0       42.000000   \n",
       "1           False             3364.0                  3638.0      113.687500   \n",
       "2           False             -118.0                   152.0        7.238095   \n",
       "3           False               -1.0                    23.0        7.666667   \n",
       "4           False               43.0                   195.0       27.857143   \n",
       "...           ...                ...                     ...             ...   \n",
       "45602       False              269.0                   553.0      110.600000   \n",
       "45603       False              661.0                   685.0       57.083333   \n",
       "45604       False              381.0                   391.0       48.875000   \n",
       "45605       False              245.0                   245.0       40.833333   \n",
       "45606       False           182199.0                182199.0      134.962222   \n",
       "\n",
       "       author_experience author_ownership  changed_file_count  entropy_bucket  \n",
       "0                  392.0            592.0                   3             low  \n",
       "1                 8249.5            632.0                  32             low  \n",
       "2                15618.0            631.0                  21             low  \n",
       "3                43014.0            621.0                   3             low  \n",
       "4                 5870.0            622.0                   7             low  \n",
       "...                  ...              ...                 ...             ...  \n",
       "45602             1381.0              1.0                   5             low  \n",
       "45603             1372.5              1.0                  12             low  \n",
       "45604             1362.5              1.0                   8             low  \n",
       "45605             1355.5              1.0                   6             low  \n",
       "45606              675.5              1.0                1350            high  \n",
       "\n",
       "[45607 rows x 37 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read commit information file into df\n",
    "commit_information = pd.read_csv(COMMIT_INFORMATION_FILE)\n",
    "\n",
    "commit_information[\"author_date_unix_timestamp\"] = pd.to_datetime(\n",
    "    commit_information[\"author_date_unix_timestamp\"], unit=\"s\"\n",
    ")\n",
    "\n",
    "# Precompute the columns dynamically\n",
    "commit_information = precompute_extended_columns(commit_information, COMMIT_INFO_EXTENDED_COLUMNS)\n",
    "\n",
    "commit_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CK_metrics(commit_hash: str, ck_metrics_folder: Path, changed_files: str) -> pd.DataFrame:\n",
    "\n",
    "    # get the CK metrics for the commit\n",
    "    ck_file = ck_metrics_folder / f'{commit_hash}.csv'\n",
    "    ck_metrics = pd.read_csv(ck_file)\n",
    "\n",
    "    # regex pattern for the absolute path prefix\n",
    "    regex_pattern = r'/home/buzluca/JIT-SDP/repositories/elasticsearch(_worker_)?[0-9]*/'\n",
    "\n",
    "    # Remove the matching prefix using regex\n",
    "    ck_metrics['file'] = ck_metrics['file'].apply(\n",
    "        lambda x: re.sub(regex_pattern, '', x)\n",
    "    )\n",
    "\n",
    "    ck_metrics['file'] = ck_metrics['file'].apply(lambda x: x.replace('\\\\', '/'))\n",
    "\n",
    "    #print(ck_metrics['file'])\n",
    "\n",
    "    # filter the CK metrics for the changed files\n",
    "    ck_metrics = ck_metrics[ck_metrics['file'].isin(changed_files)]\n",
    "    \n",
    "\n",
    "    return ck_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_CK_metrics(\"7c048973928e7074daa34172f9eb93701cb2eba9\", CK_METRICS_FOLDER, ['elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/condition/ScriptCondition.java', 'elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/transform/script/ExecutableScriptTransform.java', 'elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/transform/script/ScriptTransformFactory.java', 'elasticsearch/src/test/java/org/elasticsearch/xpack/watcher/transform/script/ScriptTransformTests.java', 'qa/smoke-test-watcher-with-painless/src/test/resources/rest-api-spec/test/watcher_painless/50_update_scripts.yaml'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_change_in_metrics(file: str, ck_metrics: pd.DataFrame, parent_ck_metrics: pd.DataFrame) -> pd.DataFrame:\n",
    "    if ck_metrics.empty or parent_ck_metrics.empty:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if data is missing\n",
    "    \n",
    "    # Initialize an empty DataFrame for the result\n",
    "    result = pd.DataFrame(columns=[\"d_\" + x for x in DELTA_METRIC_COLUMNS] + DELTA_METRIC_COLUMNS + CURRENT_STATE_ONLY_COLUMNS + COMMIT_INFO_COLUMNS + list(COMMIT_INFO_EXTENDED_COLUMNS.keys()))\n",
    "\n",
    "    # Get the file row from CK metrics\n",
    "    file_ck_metrics = ck_metrics[ck_metrics['file'] == file]\n",
    "    file_parent_ck_metrics = parent_ck_metrics[parent_ck_metrics['file'] == file]\n",
    "\n",
    "    if len(file_ck_metrics) == 0 or len(file_parent_ck_metrics) == 0:\n",
    "        # Return an empty DataFrame if the file is not found in either commit\n",
    "        # Usualy json, xml, etc. files are not found in CK metrics\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "\n",
    "    # Calculate deltas for DELTA_METRIC_COLUMNS\n",
    "    for column in DELTA_METRIC_COLUMNS:\n",
    "        result[f\"d_{column}\"] = file_ck_metrics[column].values - file_parent_ck_metrics[column].values\n",
    "        result[column] = file_ck_metrics[column].values\n",
    "\n",
    "    # Copy CURRENT_STATE_ONLY_COLUMNS directly\n",
    "    for column in CURRENT_STATE_ONLY_COLUMNS:\n",
    "        result[column] = file_ck_metrics[column].values\n",
    "\n",
    "    # Copy COMMIT_INFO_COLUMNS directly from commit_information\n",
    "    for column in COMMIT_INFO_COLUMNS:\n",
    "        result[column] = commit_information[column]\n",
    "\n",
    "    # Apply COMMIT_INFO_EXTENDED_COLUMNS functions row-wise\n",
    "    for column, func in COMMIT_INFO_EXTENDED_COLUMNS.items():\n",
    "        result[column] = commit_information[column]\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # for each commit in commit_information, get the commit hash and changed files\n",
    "    # then get the CK metrics for the commit and it's parent\n",
    "    # calculate the change in CK metrics in a seperate function.\n",
    "    # create a sepeare entry for every changed file in the commit\n",
    "    # create a new dataframe with the change in CK metrics and the commit hash and the changed file and commit information.\n",
    "    # save the new dataframe to a csv file\n",
    "\n",
    "    merged_df = pd.DataFrame(columns= [\"hash\"] + [\"d_\" + x for x in DELTA_METRIC_COLUMNS] + DELTA_METRIC_COLUMNS + CURRENT_STATE_ONLY_COLUMNS + COMMIT_INFO_COLUMNS + list(COMMIT_INFO_EXTENDED_COLUMNS.keys()))\n",
    "    count = 0\n",
    "    results = []\n",
    "    for idx, row in commit_information.iterrows():\n",
    "\n",
    "        commit_hash = row['commit_hash']\n",
    "\n",
    "        # yeah, its hacky. I know.\n",
    "        changed_files = row['fileschanged'].strip(\"[]'\").replace(\"'\", \"\").split(\", \")\n",
    "        \n",
    "        for changed_file in changed_files:\n",
    "            # Get metrics for current commit and file\n",
    "            try:\n",
    "                ck_metrics = get_CK_metrics(commit_hash, CK_METRICS_FOLDER, changed_files)\n",
    "            except:\n",
    "                #print(\"No commits\")\n",
    "                continue\n",
    "            # Get parent commit metrics\n",
    "            parent_hash = get_commit_parent_hash(commit_hash, commits)\n",
    "\n",
    "            try:\n",
    "                parent_ck_metrics = get_CK_metrics(parent_hash, CK_METRICS_FOLDER, changed_files)\n",
    "            except:\n",
    "                #print(\"No parent commits\")\n",
    "                continue\n",
    "\n",
    "            \n",
    "            if not ck_metrics.empty and not parent_ck_metrics.empty:\n",
    "                # Calculate changes\n",
    "                change_in_metrics = calculate_change_in_metrics(changed_file, ck_metrics, parent_ck_metrics)\n",
    "\n",
    "                change_in_metrics = change_in_metrics.assign(\n",
    "                    hash=commit_hash,\n",
    "                    file=changed_file\n",
    "                )\n",
    "                \n",
    "                results.append(change_in_metrics)\n",
    "                count += 1\n",
    "                print(count)\n",
    "                if(count > 10):\n",
    "                    print(len(results))\n",
    "\n",
    "                    merged_df = pd.concat(results, ignore_index=True)\n",
    "                    merged_df.to_csv(\"merged_df.csv\", index=False)\n",
    "                    print(\"Results saved to 'merged_df.csv'\")\n",
    "                    print(\"Close the program buddy...\")\n",
    "                    return\n",
    "\n",
    "    # Concatenate all collected results into a single DataFrame at the end\n",
    "    if results:\n",
    "        merged_df = pd.concat(results, ignore_index=True)\n",
    "        merged_df.to_csv(\"merged_df.csv\", index=False)\n",
    "        print(\"Results saved to 'merged_df.csv'\")\n",
    "    else:\n",
    "        print(\"No results to save.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "11\n",
      "Results saved to 'merged_df.csv'\n",
      "Close the program buddy...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Results saved to 'merged_df.csv'\n",
      "Close the program buddy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 18.6265 s\n",
      "File: C:\\Users\\nipyh\\AppData\\Local\\Temp\\ipykernel_24540\\4048654853.py\n",
      "Function: main at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def main():\n",
      "     2                                               # for each commit in commit_information, get the commit hash and changed files\n",
      "     3                                               # then get the CK metrics for the commit and it's parent\n",
      "     4                                               # calculate the change in CK metrics in a seperate function.\n",
      "     5                                               # create a sepeare entry for every changed file in the commit\n",
      "     6                                               # create a new dataframe with the change in CK metrics and the commit hash and the changed file and commit information.\n",
      "     7                                               # save the new dataframe to a csv file\n",
      "     8                                           \n",
      "     9         1     105647.0 105647.0      0.1      merged_df = pd.DataFrame(columns= [\"hash\"] + DELTA_METRIC_COLUMNS + CURRENT_STATE_ONLY_COLUMNS + COMMIT_INFO_COLUMNS + list(COMMIT_INFO_EXTENDED_COLUMNS.keys()))\n",
      "    10         1          4.0      4.0      0.0      count = 0\n",
      "    11         1          6.0      6.0      0.0      results = []\n",
      "    12       940    2512606.0   2673.0      1.3      for idx, row in commit_information.iterrows():\n",
      "    13                                           \n",
      "    14       940     250349.0    266.3      0.1          commit_hash = row['commit_hash']\n",
      "    15                                           \n",
      "    16                                                   # yeah, its hacky. I know.\n",
      "    17       940     169772.0    180.6      0.1          changed_files = row['fileschanged'].strip(\"[]'\").replace(\"'\", \"\").split(\", \")\n",
      "    18                                                   \n",
      "    19     11058      74390.0      6.7      0.0          for changed_file in changed_files:\n",
      "    20                                                       # Get metrics for current commit and file\n",
      "    21     10119      29884.0      3.0      0.0              try:\n",
      "    22     10119   86331701.0   8531.6     46.3                  ck_metrics = get_CK_metrics(commit_hash, CK_METRICS_FOLDER, changed_files)\n",
      "    23     10108      45605.0      4.5      0.0              except:\n",
      "    24                                                           #print(\"No commits\")\n",
      "    25     10108     527993.0     52.2      0.3                  continue\n",
      "    26                                                       # Get parent commit metrics\n",
      "    27        11     554063.0  50369.4      0.3              parent_hash = get_commit_parent_hash(commit_hash, commits)\n",
      "    28                                           \n",
      "    29        11         47.0      4.3      0.0              try:\n",
      "    30        11   39740826.0    4e+06     21.3                  parent_ck_metrics = get_CK_metrics(parent_hash, CK_METRICS_FOLDER, changed_files)\n",
      "    31                                                       except:\n",
      "    32                                                           #print(\"No parent commits\")\n",
      "    33                                                           continue\n",
      "    34                                           \n",
      "    35                                                       \n",
      "    36        11       4919.0    447.2      0.0              if not ck_metrics.empty and not parent_ck_metrics.empty:\n",
      "    37                                                           # Calculate changes\n",
      "    38        11    4803967.0 436724.3      2.6                  change_in_metrics = calculate_change_in_metrics(changed_file, ck_metrics, parent_ck_metrics)\n",
      "    39                                           \n",
      "    40        22     925763.0  42080.1      0.5                  change_in_metrics = change_in_metrics.assign(\n",
      "    41        11         44.0      4.0      0.0                      hash=commit_hash,\n",
      "    42        11         30.0      2.7      0.0                      file=changed_file\n",
      "    43                                                           )\n",
      "    44                                                           \n",
      "    45        11         97.0      8.8      0.0                  results.append(change_in_metrics)\n",
      "    46        11         52.0      4.7      0.0                  count += 1\n",
      "    47        11      26256.0   2386.9      0.0                  print(count)\n",
      "    48        11         74.0      6.7      0.0                  if(count > 10):\n",
      "    49         1     448496.0 448496.0      0.2                      merged_df = pd.concat(results, ignore_index=True)\n",
      "    50         1   49707276.0    5e+07     26.7                      merged_df.to_csv(\"merged_df.csv\", index=False)\n",
      "    51         1       4607.0   4607.0      0.0                      print(\"Results saved to 'merged_df.csv'\")\n",
      "    52         1        265.0    265.0      0.0                      print(\"Close the program buddy...\")\n",
      "    53         1        166.0    166.0      0.0                      return\n",
      "    54                                           \n",
      "    55                                               # Concatenate all collected results into a single DataFrame at the end\n",
      "    56                                               if results:\n",
      "    57                                                   merged_df = pd.concat(results, ignore_index=True)\n",
      "    58                                                   merged_df.to_csv(\"merged_df.csv\", index=False)\n",
      "    59                                                   print(\"Results saved to 'merged_df.csv'\")\n",
      "    60                                               else:\n",
      "    61                                                   print(\"No results to save.\")"
     ]
    }
   ],
   "source": [
    "%lprun -f main main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Results saved to 'merged_df.csv'\n",
      "Close the program buddy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.46972 s\n",
      "File: C:\\Users\\nipyh\\AppData\\Local\\Temp\\ipykernel_24540\\4286675479.py\n",
      "Function: calculate_change_in_metrics at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def calculate_change_in_metrics(file: str, ck_metrics: pd.DataFrame, parent_ck_metrics: pd.DataFrame) -> pd.DataFrame:\n",
      "     2                                               # Initialize an empty DataFrame for the result\n",
      "     3        11     984494.0  89499.5     21.0      result = pd.DataFrame(columns=DELTA_METRIC_COLUMNS + CURRENT_STATE_ONLY_COLUMNS + COMMIT_INFO_COLUMNS + list(COMMIT_INFO_EXTENDED_COLUMNS.keys()))\n",
      "     4                                           \n",
      "     5                                               # Get the file row from CK metrics\n",
      "     6        11      97751.0   8886.5      2.1      file_ck_metrics = ck_metrics[ck_metrics['file'] == file]\n",
      "     7        11      84654.0   7695.8      1.8      file_parent_ck_metrics = parent_ck_metrics[parent_ck_metrics['file'] == file]\n",
      "     8                                           \n",
      "     9                                               # Calculate deltas for DELTA_METRIC_COLUMNS\n",
      "    10       517       3030.0      5.9      0.1      for column in DELTA_METRIC_COLUMNS:\n",
      "    11       506    1893076.0   3741.3     40.3          result[column] = file_ck_metrics[column].values - file_parent_ck_metrics[column].values\n",
      "    12                                           \n",
      "    13                                               # Copy CURRENT_STATE_ONLY_COLUMNS directly\n",
      "    14        44        375.0      8.5      0.0      for column in CURRENT_STATE_ONLY_COLUMNS:\n",
      "    15        33      97125.0   2943.2      2.1          result[column] = file_ck_metrics[column].values\n",
      "    16                                           \n",
      "    17                                               # Copy COMMIT_INFO_COLUMNS directly from commit_information\n",
      "    18       165       1132.0      6.9      0.0      for column in COMMIT_INFO_COLUMNS:\n",
      "    19       154     977527.0   6347.6     20.8          result[column] = commit_information[column]\n",
      "    20                                           \n",
      "    21                                               # Apply COMMIT_INFO_EXTENDED_COLUMNS functions row-wise\n",
      "    22       121       1101.0      9.1      0.0      for column, func in COMMIT_INFO_EXTENDED_COLUMNS.items():\n",
      "    23       110     556725.0   5061.1     11.9          result[column] = commit_information[column]\n",
      "    24                                           \n",
      "    25        11        213.0     19.4      0.0      return result"
     ]
    }
   ],
   "source": [
    "%lprun -f calculate_change_in_metrics main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
