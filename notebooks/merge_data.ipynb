{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pandas future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ROOT_DIR = Path(\"..\")\n",
    "DATASET_FOLDER = ROOT_DIR / 'dataset' / 'java' / 'broadleaf'\n",
    "COMMITS_FILE = DATASET_FOLDER / 'commit_history.txt'\n",
    "COMMIT_INFORMATION_FILE = DATASET_FOLDER / 'dataset.csv'\n",
    "CK_METRICS_FOLDER = Path(\"D:\") / 'CK'\n",
    "\n",
    "# used in the commit information file\n",
    "CAS_DELIMITER = 'CAS_DELIMITER'\n",
    "\n",
    "\n",
    "##############\n",
    "# CK Metrics #\n",
    "##############\n",
    "\n",
    "# Metrics to calculate deltas for\n",
    "DELTA_METRIC_COLUMNS = [\"cbo\", \"cboModified\", \"fanin\", \"fanout\", \"wmc\", \n",
    "    \"dit\", \"noc\", \"rfc\", \"lcom\", \"lcom*\", \"tcc\", \"lcc\", \n",
    "    \"totalMethodsQty\", \"staticMethodsQty\", \"publicMethodsQty\", \"privateMethodsQty\", \n",
    "    \"protectedMethodsQty\", \"defaultMethodsQty\", \"visibleMethodsQty\", \n",
    "    \"abstractMethodsQty\", \"finalMethodsQty\", \"synchronizedMethodsQty\", \n",
    "    \"totalFieldsQty\", \"staticFieldsQty\", \"publicFieldsQty\", \"privateFieldsQty\", \n",
    "    \"protectedFieldsQty\", \"defaultFieldsQty\", \"finalFieldsQty\", \"synchronizedFieldsQty\", \n",
    "    \"nosi\", \"loc\", \"returnQty\", \"loopQty\", \"comparisonsQty\", \"tryCatchQty\", \n",
    "    \"parenthesizedExpsQty\", \"stringLiteralsQty\", \"numbersQty\", \n",
    "    \"assignmentsQty\", \"mathOperationsQty\", \"variablesQty\", \"maxNestedBlocksQty\", \n",
    "    \"anonymousClassesQty\", \"innerClassesQty\", \"lambdasQty\",\n",
    "    \"uniqueWordsQty\", \"modifiers\", \"logStatementsQty\"]\n",
    "\n",
    "CURRENT_STATE_ONLY_COLUMNS = [\n",
    "    \"class\", \"type\"\n",
    "]\n",
    "\n",
    "######################\n",
    "# Commit Gru Metrics #\n",
    "######################\n",
    "\n",
    "COMMIT_INFO_COLUMNS = [\n",
    "    \"fix\",               # Boolean\n",
    "    \"classification\",    # Categorical\n",
    "    #\"linked\",           # Boolean                     | commit guru related\n",
    "    \"contains_bug\",      # Boolean                     | truth value\n",
    "    \"entrophy\",          # Numeric\n",
    "    \"la\",                # Lines Added\n",
    "    \"ld\",                # Lines Deleted\n",
    "    #\"fileschanged\",      # Count of files changed # \n",
    "    \"ndev\",              # Number of developers\n",
    "    \"age\",               # Average file age\n",
    "    \"exp\",               # Developer experience\n",
    "    \"rexp\",              # Recent experience\n",
    "    \"sexp\",              # Subsystem experience\n",
    "    \"glm_probability\",   # Numeric                      | all 0, not useful\n",
    "    \"author_date_unix_timestamp\" # Date of commit\n",
    "]\n",
    "\n",
    "# Updated COMMIT_INFO_EXTENDED_COLUMNS with vectorized lambdas\n",
    "COMMIT_INFO_EXTENDED_COLUMNS = {\n",
    "    \"time_of_day\": lambda df: df[\"author_date_unix_timestamp\"].dt.hour,\n",
    "    \"day_of_week\": lambda df: df[\"author_date_unix_timestamp\"].dt.dayofweek,\n",
    "    \"is_weekend\": lambda df: df[\"author_date_unix_timestamp\"].dt.dayofweek > 4,\n",
    "    \"net_lines_changed\": lambda df: df[\"la\"] - df[\"ld\"],\n",
    "    \"absolute_lines_changed\": lambda df: abs(df[\"la\"] + df[\"ld\"]),\n",
    "    \"lines_per_file\": lambda df: (df[\"la\"] + df[\"ld\"]) / (df[\"fileschanged\"].str.count(\",\") + 1),\n",
    "    \"author_experience\": lambda df: df[\"exp\"],\n",
    "    \"author_ownership\": lambda df: df[\"ndev\"],\n",
    "    \"changed_file_count\": lambda df: df[\"fileschanged\"].str.count(\",\") + 1,\n",
    "    \"entropy_bucket\": lambda df: pd.cut(\n",
    "        df[\"entrophy\"], bins=3, labels=[\"low\", \"medium\", \"high\"]\n",
    "    ),\n",
    "    \"num_files_changed\": lambda df: df[\"fileschanged\"].str.count(\",\") + 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commit_parent_hash(commit_hash: str, commits_df: pd.DataFrame) -> str:\n",
    "\n",
    "    # find the commit index in the dataframe and return previous hash\n",
    "    commit_index = commits_df[commits_df['hash'] == commit_hash].index[0]\n",
    "    # retunr previous hash\n",
    "    try:\n",
    "        parent_hash = commits_df.iloc[commit_index + 1]['hash']\n",
    "    except IndexError:\n",
    "        parent_hash = None\n",
    "    return parent_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute extended columns dynamically\n",
    "def precompute_extended_columns(commit_info_df, extended_columns):\n",
    "    for column, func in extended_columns.items():\n",
    "        if callable(func):\n",
    "            # Apply the function across the DataFrame without axis=1\n",
    "            commit_info_df[column] = func(commit_info_df)\n",
    "        else:\n",
    "            raise ValueError(f\"Function for column '{column}' must be callable\")\n",
    "    return commit_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7b8f23ee797efd78092dffc89048dda0a4c09a98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>916521e5543af19d06383acff1d1d2f635c5a301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd1e0d8571c707aef7baf9fea03cd10e17a7fe0c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>071f980fa00c1a64367a9e8d002398a88f18bb75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e56ef02e15d6645743b150f2e148c62ba85911ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18653</th>\n",
       "      <td>044a99f0d8cfd3d11e85f45cd5bfc210cd509980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18654</th>\n",
       "      <td>59f3abc25a731e1d901416b0c06c88aa6fae1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18655</th>\n",
       "      <td>c89a41d0b89c1cf5467b8eb5948132005b8301ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18656</th>\n",
       "      <td>2bf902b5f0c7e6ad29a515406d92a0307b66e1aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18657</th>\n",
       "      <td>0b84ec28bdb41d9e5bbf8eef4f73ab09055e24c9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18658 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           hash\n",
       "0      7b8f23ee797efd78092dffc89048dda0a4c09a98\n",
       "1      916521e5543af19d06383acff1d1d2f635c5a301\n",
       "2      fd1e0d8571c707aef7baf9fea03cd10e17a7fe0c\n",
       "3      071f980fa00c1a64367a9e8d002398a88f18bb75\n",
       "4      e56ef02e15d6645743b150f2e148c62ba85911ed\n",
       "...                                         ...\n",
       "18653  044a99f0d8cfd3d11e85f45cd5bfc210cd509980\n",
       "18654  59f3abc25a731e1d901416b0c06c88aa6fae1477\n",
       "18655  c89a41d0b89c1cf5467b8eb5948132005b8301ee\n",
       "18656  2bf902b5f0c7e6ad29a515406d92a0307b66e1aa\n",
       "18657  0b84ec28bdb41d9e5bbf8eef4f73ab09055e24c9\n",
       "\n",
       "[18658 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read commit history\n",
    "commits = pd.read_csv(COMMITS_FILE, header=None, names=['hash'])\n",
    "commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_hash</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_date_unix_timestamp</th>\n",
       "      <th>author_email</th>\n",
       "      <th>author_date</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>fix</th>\n",
       "      <th>classification</th>\n",
       "      <th>linked</th>\n",
       "      <th>contains_bug</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>net_lines_changed</th>\n",
       "      <th>absolute_lines_changed</th>\n",
       "      <th>lines_per_file</th>\n",
       "      <th>author_experience</th>\n",
       "      <th>author_ownership</th>\n",
       "      <th>changed_file_count</th>\n",
       "      <th>entropy_bucket</th>\n",
       "      <th>num_files_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e296c698b83e320ff15c4ec1ca9258e188ff867c</td>\n",
       "      <td>KatrukOV</td>\n",
       "      <td>2024-10-21 13:22:25</td>\n",
       "      <td>KatrukOV@gmail.com</td>\n",
       "      <td>Mon Oct 21 16:22:25 2024 +0300</td>\n",
       "      <td>QA-5314: created MessageService, BLCMessageUti...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>2818.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9aa562f432ccfec587895b633c908eaa85f85f36</td>\n",
       "      <td>Roman Mosiienko</td>\n",
       "      <td>2024-10-08 12:39:03</td>\n",
       "      <td>roman.mosiienko@gmail.com</td>\n",
       "      <td>Tue Oct 8 15:39:03 2024 +0300</td>\n",
       "      <td>BroadleafCommerce/QA#5293 (#3026)Fixed typo in...</td>\n",
       "      <td>True</td>\n",
       "      <td>Corrective</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83068da492974cd27ab0fcd85700af3e369d5490</td>\n",
       "      <td>KatrukOV</td>\n",
       "      <td>2024-10-07 15:53:10</td>\n",
       "      <td>KatrukOV@gmail.com</td>\n",
       "      <td>Mon Oct 7 18:53:10 2024 +0300</td>\n",
       "      <td>QA-5309: updated hibernate version; fixed test...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2815.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ed8f87a110ddcae69668aef0a4d8d4f4d292574d</td>\n",
       "      <td>KatrukOV</td>\n",
       "      <td>2024-10-02 08:36:52</td>\n",
       "      <td>KatrukOV@gmail.com</td>\n",
       "      <td>Wed Oct 2 11:36:52 2024 +0300</td>\n",
       "      <td>QA-5308: fixed validateIfProductIsProdRecord()...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2814.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9ca686b7a68e010d4d22d7ffb59d078d4c138109</td>\n",
       "      <td>Roman Mosiienko</td>\n",
       "      <td>2024-08-13 14:17:20</td>\n",
       "      <td>roman.mosiienko@gmail.com</td>\n",
       "      <td>Tue Aug 13 17:17:20 2024 +0300</td>\n",
       "      <td>BroadleafCommerce/QA#5294 (#3019)Added new con...</td>\n",
       "      <td>False</td>\n",
       "      <td>Feature Addition</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10141</th>\n",
       "      <td>939598ee321b80c8272358a9967ab2bb05fb0bbb</td>\n",
       "      <td>Jonathan Ball</td>\n",
       "      <td>2009-01-08 20:42:13</td>\n",
       "      <td>jball@credera.com</td>\n",
       "      <td>Thu Jan 8 20:42:13 2009 +0000</td>\n",
       "      <td>add login to query for password change require...</td>\n",
       "      <td>False</td>\n",
       "      <td>Feature Addition</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>366.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>31.833333</td>\n",
       "      <td>237.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>low</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>539acc6e622672d2fb011702ad47bdaaf35a7c79</td>\n",
       "      <td>Jeff Fischer</td>\n",
       "      <td>2009-01-07 19:10:55</td>\n",
       "      <td>jfischer@broadleafcommerce.org</td>\n",
       "      <td>Wed Jan 7 19:10:55 2009 +0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>low</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10143</th>\n",
       "      <td>d6a459082f1085aeedd5895b46ca7a1fd3a54b00</td>\n",
       "      <td>Jonathan Ball</td>\n",
       "      <td>2008-12-30 21:33:13</td>\n",
       "      <td>jball@credera.com</td>\n",
       "      <td>Tue Dec 30 21:33:13 2008 +0000</td>\n",
       "      <td>add methods to lookup user</td>\n",
       "      <td>False</td>\n",
       "      <td>Feature Addition</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>106.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10144</th>\n",
       "      <td>d8a646f6819a212257741cc7071998093a34b674</td>\n",
       "      <td>Jonathan Ball</td>\n",
       "      <td>2008-12-30 19:16:59</td>\n",
       "      <td>jball@credera.com</td>\n",
       "      <td>Tue Dec 30 19:16:59 2008 +0000</td>\n",
       "      <td>add UserService and implementation</td>\n",
       "      <td>False</td>\n",
       "      <td>Feature Addition</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>ed9ccaee0f77967b401f57d0cd975729a674de42</td>\n",
       "      <td>Jonathan Ball</td>\n",
       "      <td>2008-12-30 17:59:43</td>\n",
       "      <td>jball@credera.com</td>\n",
       "      <td>Tue Dec 30 17:59:43 2008 +0000</td>\n",
       "      <td>initial entities and services for User and Use...</td>\n",
       "      <td>False</td>\n",
       "      <td>Feature Addition</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>530.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>49.272727</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>low</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10146 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    commit_hash      author_name  \\\n",
       "0      e296c698b83e320ff15c4ec1ca9258e188ff867c         KatrukOV   \n",
       "1      9aa562f432ccfec587895b633c908eaa85f85f36  Roman Mosiienko   \n",
       "2      83068da492974cd27ab0fcd85700af3e369d5490         KatrukOV   \n",
       "3      ed8f87a110ddcae69668aef0a4d8d4f4d292574d         KatrukOV   \n",
       "4      9ca686b7a68e010d4d22d7ffb59d078d4c138109  Roman Mosiienko   \n",
       "...                                         ...              ...   \n",
       "10141  939598ee321b80c8272358a9967ab2bb05fb0bbb    Jonathan Ball   \n",
       "10142  539acc6e622672d2fb011702ad47bdaaf35a7c79     Jeff Fischer   \n",
       "10143  d6a459082f1085aeedd5895b46ca7a1fd3a54b00    Jonathan Ball   \n",
       "10144  d8a646f6819a212257741cc7071998093a34b674    Jonathan Ball   \n",
       "10145  ed9ccaee0f77967b401f57d0cd975729a674de42    Jonathan Ball   \n",
       "\n",
       "      author_date_unix_timestamp                    author_email  \\\n",
       "0            2024-10-21 13:22:25              KatrukOV@gmail.com   \n",
       "1            2024-10-08 12:39:03       roman.mosiienko@gmail.com   \n",
       "2            2024-10-07 15:53:10              KatrukOV@gmail.com   \n",
       "3            2024-10-02 08:36:52              KatrukOV@gmail.com   \n",
       "4            2024-08-13 14:17:20       roman.mosiienko@gmail.com   \n",
       "...                          ...                             ...   \n",
       "10141        2009-01-08 20:42:13               jball@credera.com   \n",
       "10142        2009-01-07 19:10:55  jfischer@broadleafcommerce.org   \n",
       "10143        2008-12-30 21:33:13               jball@credera.com   \n",
       "10144        2008-12-30 19:16:59               jball@credera.com   \n",
       "10145        2008-12-30 17:59:43               jball@credera.com   \n",
       "\n",
       "                          author_date  \\\n",
       "0      Mon Oct 21 16:22:25 2024 +0300   \n",
       "1       Tue Oct 8 15:39:03 2024 +0300   \n",
       "2       Mon Oct 7 18:53:10 2024 +0300   \n",
       "3       Wed Oct 2 11:36:52 2024 +0300   \n",
       "4      Tue Aug 13 17:17:20 2024 +0300   \n",
       "...                               ...   \n",
       "10141   Thu Jan 8 20:42:13 2009 +0000   \n",
       "10142   Wed Jan 7 19:10:55 2009 +0000   \n",
       "10143  Tue Dec 30 21:33:13 2008 +0000   \n",
       "10144  Tue Dec 30 19:16:59 2008 +0000   \n",
       "10145  Tue Dec 30 17:59:43 2008 +0000   \n",
       "\n",
       "                                          commit_message    fix  \\\n",
       "0      QA-5314: created MessageService, BLCMessageUti...  False   \n",
       "1      BroadleafCommerce/QA#5293 (#3026)Fixed typo in...   True   \n",
       "2      QA-5309: updated hibernate version; fixed test...  False   \n",
       "3      QA-5308: fixed validateIfProductIsProdRecord()...  False   \n",
       "4      BroadleafCommerce/QA#5294 (#3019)Added new con...  False   \n",
       "...                                                  ...    ...   \n",
       "10141  add login to query for password change require...  False   \n",
       "10142                                                NaN  False   \n",
       "10143                         add methods to lookup user  False   \n",
       "10144                 add UserService and implementation  False   \n",
       "10145  initial entities and services for User and Use...  False   \n",
       "\n",
       "         classification  linked  contains_bug  ...  day_of_week  is_weekend  \\\n",
       "0                   NaN   False         False  ...            0       False   \n",
       "1            Corrective    True         False  ...            1       False   \n",
       "2                   NaN   False         False  ...            0       False   \n",
       "3                   NaN   False         False  ...            2       False   \n",
       "4      Feature Addition   False         False  ...            1       False   \n",
       "...                 ...     ...           ...  ...          ...         ...   \n",
       "10141  Feature Addition   False         False  ...            3       False   \n",
       "10142               NaN   False         False  ...            2       False   \n",
       "10143  Feature Addition   False         False  ...            1       False   \n",
       "10144  Feature Addition   False         False  ...            1       False   \n",
       "10145  Feature Addition   False         False  ...            1       False   \n",
       "\n",
       "       net_lines_changed  absolute_lines_changed  lines_per_file  \\\n",
       "0                   87.0                    91.0       22.750000   \n",
       "1                    0.0                     2.0        2.000000   \n",
       "2                    0.0                     4.0        2.000000   \n",
       "3                    4.0                     8.0        8.000000   \n",
       "4                    4.0                     6.0        3.000000   \n",
       "...                  ...                     ...             ...   \n",
       "10141              366.0                   382.0       31.833333   \n",
       "10142              372.0                   372.0       14.880000   \n",
       "10143               13.0                    13.0        3.250000   \n",
       "10144               44.0                    52.0       10.400000   \n",
       "10145              530.0                   542.0       49.272727   \n",
       "\n",
       "       author_experience  author_ownership changed_file_count  entropy_bucket  \\\n",
       "0                 2818.5              53.0                  4             low   \n",
       "1                   26.0              52.0                  1             low   \n",
       "2                 2815.5              52.0                  2             low   \n",
       "3                 2814.0              52.0                  1             low   \n",
       "4                   23.5              52.0                  2             low   \n",
       "...                  ...               ...                ...             ...   \n",
       "10141              237.5               1.0                 12             low   \n",
       "10142               24.0               1.0                 25             low   \n",
       "10143              106.5               2.0                  4             low   \n",
       "10144               19.0               2.0                  5             low   \n",
       "10145                5.0               2.0                 11             low   \n",
       "\n",
       "       num_files_changed  \n",
       "0                      4  \n",
       "1                      1  \n",
       "2                      2  \n",
       "3                      1  \n",
       "4                      2  \n",
       "...                  ...  \n",
       "10141                 12  \n",
       "10142                 25  \n",
       "10143                  4  \n",
       "10144                  5  \n",
       "10145                 11  \n",
       "\n",
       "[10146 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read commit information file into df\n",
    "commit_information = pd.read_csv(COMMIT_INFORMATION_FILE)\n",
    "\n",
    "commit_information[\"author_date_unix_timestamp\"] = pd.to_datetime(\n",
    "    commit_information[\"author_date_unix_timestamp\"], unit=\"s\"\n",
    ")\n",
    "\n",
    "# Precompute the columns dynamically\n",
    "commit_information = precompute_extended_columns(commit_information, COMMIT_INFO_EXTENDED_COLUMNS)\n",
    "\n",
    "commit_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Preload changed_files for each commit\n",
    "\n",
    "# Create a dictionary to store preloaded changed files\n",
    "_changed_files_cache = {}\n",
    "\n",
    "def preload_changed_files(commits_df: pd.DataFrame) -> int:\n",
    "\n",
    "    global _changed_files_cache\n",
    "\n",
    "    \"\"\"    # check if json file exists\n",
    "    if os.path.exists('changed_files_cache.json'):\n",
    "        with open('changed_files_cache.json', 'r') as f:\n",
    "            _changed_files_cache = json.load(f)\n",
    "            print(len(_changed_files_cache))\n",
    "\n",
    "        return len(_changed_files_cache)\"\"\"\n",
    "    \n",
    "    # check if pickle file exists\n",
    "    if os.path.exists('changed_files_cache.pkl'):\n",
    "        with open('changed_files_cache.pkl', 'rb') as f:\n",
    "            _changed_files_cache = pickle.load(f)\n",
    "            print(len(_changed_files_cache))\n",
    "\n",
    "        return len(_changed_files_cache)\n",
    "\n",
    "    i = 0\n",
    "    for commit_hash in commits_df['commit_hash']:\n",
    "        if i % 100 == 0:  # Update progress\n",
    "            print(f\"\\rLoading changed files: {i}/{len(commits_df)}\", end='', flush=True)\n",
    "        i += 1\n",
    "        # Get the first (and only) value from the Series and then apply string operations\n",
    "        files_str = commits_df.loc[commits_df['commit_hash'] == commit_hash, 'fileschanged'].iloc[0]\n",
    "        changed_files = files_str.strip(\"[]'\").replace(\"'\", \"\").split(\", \")\n",
    "        _changed_files_cache[commit_hash] = changed_files\n",
    "\n",
    "\n",
    "    # Save changed_files_cache\n",
    "    #with open('changed_files_cache.json', 'w') as f:\n",
    "        #json.dump(_changed_files_cache, f)\n",
    "    \n",
    "    #print(\"Saved changed_files_cache at as json file\")\n",
    "\n",
    "    return len(_changed_files_cache)\n",
    "\n",
    "\n",
    "def get_changed_files(commit_hash: str, commits_df: pd.DataFrame) -> list[str]:\n",
    "    global _changed_files_cache\n",
    "    if commit_hash not in _changed_files_cache.keys():\n",
    "        return []  # Return empty list if commit not found\n",
    "    \n",
    "    return _changed_files_cache[commit_hash]\n",
    "\n",
    "# Create a dictionary to store preloaded metrics\n",
    "_ck_metrics_cache = {}\n",
    "\n",
    "def preload_ck_metrics(ck_metrics_folder: Path):\n",
    "    #return\n",
    "    \n",
    "    global _ck_metrics_cache\n",
    "\n",
    "    \"\"\"    # check if json file exists\n",
    "    if os.path.exists('ck_metrics_cache.json'):\n",
    "        with open('ck_metrics_cache.json', 'r') as f:\n",
    "            cache = json.load(f)\n",
    "            _ck_metrics_cache = { key: pd.read_csv(value) for key, value in cache.items() }\n",
    "\n",
    "        return len(_ck_metrics_cache)\"\"\"\n",
    "    # load pickel file\n",
    "    if os.path.exists('ck_metrics_cache.pkl'):\n",
    "        with open('ck_metrics_cache.pkl', 'rb') as f:\n",
    "            _ck_metrics_cache = pickle.load(f)\n",
    "            return len(_ck_metrics_cache)\n",
    "    \n",
    "    regex_pattern = r'/home/buzluca/JIT-SDP/repositories/broadleaf(_worker_)?[0-9]*/'\n",
    "\n",
    "    i = 0\n",
    "    for csv_file in ck_metrics_folder.glob('*.csv'):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"\\rLoading CK files: {i}\", end='', flush=True)\n",
    "        i+= 1\n",
    "        commit_hash = csv_file.stem  # Get filename without extension\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Clean paths when loading the data\n",
    "        df['file'] = df['file'].str.replace(regex_pattern, '', regex=True).str.replace('\\\\', '/')\n",
    "        \n",
    "        # this line was first intended to reduce the size of the data in ram\n",
    "        # but we need all the data to calculate deltas, as we dont know which files are changed for preceeding and proceeding commits \n",
    "        #df = df[df['file'].isin(get_changed_files(commit_hash, commit_information))]\n",
    "        \n",
    "        _ck_metrics_cache[commit_hash] = df\n",
    "\n",
    "    #serializable_ck_cache = {\n",
    "    #    k: v.to_dict('records') if isinstance(v, pd.DataFrame) else v \n",
    "    #    for k, v in _ck_metrics_cache.items()\n",
    "    #}\n",
    "\n",
    "    #with open('ck_metrics_cache.json', 'w') as f:\n",
    "        #json.dump(serializable_ck_cache, f)\n",
    "\n",
    "    print(\"Saved ck_metrics_cache as json file\")\n",
    "    \n",
    "    return len(_ck_metrics_cache)\n",
    "\n",
    "# Modify the function to use cached data\n",
    "def get_CK_metrics(commit_hash: str, ck_metrics_folder: Path, changed_file: str) -> pd.DataFrame:\n",
    "    \"\"\"    # load from disk\n",
    "    df = pd.read_csv(ck_metrics_folder / f\"{commit_hash}.csv\")\n",
    "\n",
    "    # Clean paths when loading the data\n",
    "    df['file'] = df['file'].str.replace(r'/home/buzluca/JIT-SDP/repositories/broadleaf(_worker_)?[0-9]*/', '', regex=True).str.replace('\\\\', '/')\n",
    "\n",
    "    return df[df['file'] == changed_file]\"\"\"\n",
    "\n",
    "\n",
    "    #return\n",
    "    \n",
    "    if not _ck_metrics_cache:\n",
    "        preload_ck_metrics(ck_metrics_folder)\n",
    "    \n",
    "    if commit_hash not in _ck_metrics_cache.keys():\n",
    "        return pd.DataFrame()  # Return empty DataFrame if commit not found\n",
    "        \n",
    "    ############################################### BUNU DÜŞÜN !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! \n",
    "    #e = _ck_metrics_cache[commit_hash]\n",
    "    #a = 1\n",
    "    result_df = _ck_metrics_cache[commit_hash][_ck_metrics_cache[commit_hash]['file'] == changed_file]\n",
    "    if result_df.empty:\n",
    "        # Create a DataFrame with zeros using the same columns as the original CK metrics\n",
    "        zero_df = pd.DataFrame(0, index=[0], columns=_ck_metrics_cache[commit_hash].columns)\n",
    "        return zero_df\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('changed_files_cache.json', 'w') as f:\n",
    "    json.dump(_changed_files_cache, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_change_in_metrics(\n",
    "    ck_metrics: pd.DataFrame,\n",
    "    parent_ck_metrics: pd.DataFrame,\n",
    "    commit_information: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given CK metrics for the current commit (`ck_metrics`) and the parent commit (`parent_ck_metrics`),\n",
    "    calculate delta metrics (`d_<metric>`) for columns in `DELTA_METRIC_COLUMNS`.\n",
    "    Also copy over current metrics, CURRENT_STATE_ONLY_COLUMNS, and commit info.\n",
    "    \"\"\"\n",
    "\n",
    "    # If either DataFrame is empty, or if \"class\" is missing, we can't align data\n",
    "    if ck_metrics.empty or parent_ck_metrics.empty:\n",
    "        return pd.DataFrame()\n",
    "    if \"class\" not in ck_metrics.columns or \"class\" not in parent_ck_metrics.columns:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 1) Identify modified vs. new classes\n",
    "    modified_classes = set(ck_metrics[\"class\"]).intersection(parent_ck_metrics[\"class\"])\n",
    "    new_classes = set(ck_metrics[\"class\"]) - set(parent_ck_metrics[\"class\"])\n",
    "\n",
    "    # 2) Filter dataframes to relevant rows\n",
    "    common_class_ck = ck_metrics[ck_metrics[\"class\"].isin(modified_classes)]\n",
    "    common_class_parent = parent_ck_metrics[parent_ck_metrics[\"class\"].isin(modified_classes)]\n",
    "    new_class_ck = ck_metrics[ck_metrics[\"class\"].isin(new_classes)]\n",
    "\n",
    "    # If there's no overlap and no new classes, nothing to do\n",
    "    if common_class_ck.empty and new_class_ck.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 3) Make sure we have both the \"class\" column AND use it as the index\n",
    "    #    (drop=False keeps \"class\" in the columns as well)\n",
    "    common_class_ck_aligned = common_class_ck.set_index(\"class\", drop=False)\n",
    "    common_class_parent_aligned = common_class_parent.set_index(\"class\", drop=False)\n",
    "    new_class_ck_aligned = new_class_ck.set_index(\"class\", drop=False)\n",
    "\n",
    "    # 4) Compute delta metrics\n",
    "    #    - \"modified\" classes: current - parent\n",
    "    #    - \"new\" classes: same as current (no parent => delta = current)\n",
    "    if not common_class_ck_aligned.empty and not common_class_parent_aligned.empty:\n",
    "        delta_modified = common_class_ck_aligned[DELTA_METRIC_COLUMNS].subtract(\n",
    "            common_class_parent_aligned[DELTA_METRIC_COLUMNS],\n",
    "            #fill_value=0  # or omit if you prefer NaN for missing\n",
    "        )\n",
    "    else:\n",
    "        # No modified classes, so create an empty DataFrame with the needed columns\n",
    "        delta_modified = pd.DataFrame(columns=DELTA_METRIC_COLUMNS)\n",
    "\n",
    "    # \"New\" classes => delta is the same as current\n",
    "    delta_new = new_class_ck_aligned[DELTA_METRIC_COLUMNS]\n",
    "    delta_combined = pd.concat([delta_modified, delta_new], axis=0)\n",
    "\n",
    "    # 5) Current metric values (both modified + new)\n",
    "    current_modified = common_class_ck_aligned[DELTA_METRIC_COLUMNS] if not common_class_ck_aligned.empty else pd.DataFrame(columns=DELTA_METRIC_COLUMNS)\n",
    "    current_new = new_class_ck_aligned[DELTA_METRIC_COLUMNS] if not new_class_ck_aligned.empty else pd.DataFrame(columns=DELTA_METRIC_COLUMNS)\n",
    "    current_metrics_combined = pd.concat([current_modified, current_new], axis=0)\n",
    "\n",
    "    # 6) Current-state-only columns (e.g., [\"class\", \"type\"])\n",
    "    #    Because we used drop=False above, \"class\" is still in the columns.\n",
    "    current_state_modified = common_class_ck_aligned[CURRENT_STATE_ONLY_COLUMNS] if not common_class_ck_aligned.empty else pd.DataFrame(columns=CURRENT_STATE_ONLY_COLUMNS)\n",
    "    current_state_new = new_class_ck_aligned[CURRENT_STATE_ONLY_COLUMNS] if not new_class_ck_aligned.empty else pd.DataFrame(columns=CURRENT_STATE_ONLY_COLUMNS)\n",
    "    current_state_combined = pd.concat([current_state_modified, current_state_new], axis=0)\n",
    "\n",
    "    # 7) Commit info: typically 1 row per commit\n",
    "    if commit_information.empty:\n",
    "        # Create empty placeholders for all commit columns\n",
    "        commit_info_df = pd.DataFrame(columns=COMMIT_INFO_COLUMNS + list(COMMIT_INFO_EXTENDED_COLUMNS.keys()))\n",
    "    else:\n",
    "        # Filter just the relevant columns\n",
    "        commit_info_df = commit_information[COMMIT_INFO_COLUMNS + list(COMMIT_INFO_EXTENDED_COLUMNS.keys())]\n",
    "        if len(commit_info_df) == 1:\n",
    "            # Replicate that one row for all classes\n",
    "            commit_info_df = pd.concat([commit_info_df]*len(delta_combined), ignore_index=True)\n",
    "        else:\n",
    "            # Otherwise, you'll need a more specific matching strategy\n",
    "            # (Assuming 1 commit => replicate row 0 is the simplest fallback)\n",
    "            commit_info_df = pd.concat([commit_info_df.iloc[[0]]]*len(delta_combined), ignore_index=True)\n",
    "\n",
    "    # 8) Build final DataFrame\n",
    "    #    Start with the same index as delta_combined\n",
    "    final_df = pd.DataFrame(index=delta_combined.index)\n",
    "\n",
    "    # a) Add \"d_<metric>\" columns\n",
    "    final_df[[f\"d_{col}\" for col in DELTA_METRIC_COLUMNS]] = delta_combined[DELTA_METRIC_COLUMNS]\n",
    "\n",
    "    # b) Add current metrics\n",
    "    final_df[DELTA_METRIC_COLUMNS] = current_metrics_combined[DELTA_METRIC_COLUMNS]\n",
    "\n",
    "    # c) Add current-state columns (including \"class\" since we used drop=False)\n",
    "    final_df[CURRENT_STATE_ONLY_COLUMNS] = current_state_combined[CURRENT_STATE_ONLY_COLUMNS]\n",
    "\n",
    "    # d) Add commit info columns\n",
    "    # commit_info is single row, so we can just copy it to all rows\n",
    "    commit_info_df.index = final_df.index  # line up by row\n",
    "    final_df = final_df.join(commit_info_df)\n",
    "\n",
    "    # 9) Optionally reset index so \"class\" is a normal column, not the index\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "def setup_logger():\n",
    "    # Create logs directory if it doesn't exist\n",
    "    log_dir = ROOT_DIR / 'logs'\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create a logger\n",
    "    logger = logging.getLogger('commit_processor')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Create file handler with timestamp in filename\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_file = log_dir / f'commit_processing_{timestamp}.log'\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    \n",
    "    # Create console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    \n",
    "    # Create formatter\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    \n",
    "    # Add handlers to logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading changed files...\n",
      "10146\n",
      "Changed files preloaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preloading changed files...\")\n",
    "preload_changed_files(commit_information)\n",
    "print(\"Changed files preloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10146\n"
     ]
    }
   ],
   "source": [
    "print(len(_changed_files_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading CK metrics...\n",
      "CK metrics preloaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preloading CK metrics...\")\n",
    "preload_ck_metrics(CK_METRICS_FOLDER)\n",
    "print(\"CK metrics preloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13264\n"
     ]
    }
   ],
   "source": [
    "print(len(_ck_metrics_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0006af0a508d85e5272619e42d84de6cd274ba65',\n",
       " '000c163f71928338e659bd059d8018f0b1b1df2a',\n",
       " '00162a14cd5f51b3ca5107972402dc8174773089',\n",
       " '001668c70ddafbd5710f8b28f8efa3c61a665b8c',\n",
       " '0016ea29ef69b8721dfd45c6e0b1647ec6f20794']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(_ck_metrics_cache.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Save caches as pickle as well\\nwith open('changed_files_cache.pkl', 'wb') as f:\\n    pickle.dump(_changed_files_cache, f)\\n\\nwith open('ck_metrics_cache.pkl', 'wb') as f:\\n    pickle.dump(_ck_metrics_cache, f)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Save caches as pickle as well\n",
    "with open('changed_files_cache.pkl', 'wb') as f:\n",
    "    pickle.dump(_changed_files_cache, f)\n",
    "\n",
    "with open('ck_metrics_cache.pkl', 'wb') as f:\n",
    "    pickle.dump(_ck_metrics_cache, f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_file(file: str) -> bool:\n",
    "    return file.endswith('.java') and not file.endswith('package-info.java') and not \"test\" in file.lower() and not \"example\" in file.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "def main():\n",
    "    # for each commit in commit_information, get the commit hash and changed files\n",
    "    # then get the CK metrics for the commit and it's parent\n",
    "    # calculate the change in CK metrics in a seperate function.\n",
    "    # create a sepeare entry for every changed file in the commit\n",
    "    # create a new dataframe with the change in CK metrics and the commit hash and the changed file and commit information.\n",
    "    # save the new dataframe to a csv file\n",
    "    \n",
    "    \n",
    "    # Initialize logger\n",
    "    logger = setup_logger()\n",
    "    \n",
    "    \n",
    "    # Create locks\n",
    "    results_lock = threading.Lock()\n",
    "    logger_lock = threading.Lock()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    \n",
    "    def process_commit(row_data):\n",
    "        idx, row = row_data\n",
    "        commit_hash = row['commit_hash']\n",
    "        \n",
    "        with logger_lock:\n",
    "            logger.info(f\"Processing commit {commit_hash} | {idx + 1} of {len(commit_information)} commits | Number of merged commits: {len(results)}\")\n",
    "            \n",
    "        #changed_files = row['fileschanged'].strip(\"[]'\").replace(\"'\", \"\").split(\", \")\n",
    "\n",
    "        changed_files = get_changed_files(commit_hash, commit_information)\n",
    "\n",
    "        # filter changed files\n",
    "        changed_files = [file for file in changed_files if is_valid_file(file)]\n",
    "        \n",
    "        changed_file_idx = 0\n",
    "\n",
    "        for changed_file in changed_files:\n",
    "            \n",
    "            changed_file_idx += 1\n",
    "\n",
    "            try:\n",
    "                ck_metrics = get_CK_metrics(commit_hash, CK_METRICS_FOLDER, changed_file)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            parent_hash = get_commit_parent_hash(commit_hash, commits)\n",
    "            \n",
    "            try:\n",
    "                parent_ck_metrics = get_CK_metrics(parent_hash, CK_METRICS_FOLDER, changed_file)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "                \n",
    "            if not ck_metrics.empty and not parent_ck_metrics.empty:\n",
    "                commit_information_row = commit_information[commit_information['commit_hash'] == commit_hash]\n",
    "                change_in_metrics = calculate_change_in_metrics(ck_metrics, parent_ck_metrics, commit_information_row)\n",
    "\n",
    "                if change_in_metrics.empty:\n",
    "                    # no source code file is modified or added\n",
    "                    continue\n",
    "\n",
    "                # print \"a\" if there is more than 5 nan values in change_in_metrics\n",
    "                #if change_in_metrics.isnull().sum().sum() > 5:\n",
    "                    #print(\"a\")\n",
    "                \n",
    "                change_in_metrics.loc[:, ['hash', 'file']] = commit_hash, changed_file\n",
    "                \n",
    "                with results_lock:\n",
    "                    results.append(change_in_metrics)\n",
    "                    with logger_lock:\n",
    "                        if changed_file_idx % 100 == 0:\n",
    "                            logger.info(f\"Merging commit {commit_hash} | {changed_file_idx} file of {len(changed_files)} changed files | Number of merged commits: {len(results)}\")\n",
    "                        #logger.info(f\"Merged commit {commit_hash} | {changed_file_idx} file of {len(changed_files)} changed files, Number of merged commits: {len(results)}\")\n",
    "                \n",
    "\n",
    "    \n",
    "    # Use ThreadPoolExecutor to parallelize the processing\n",
    "    \"\"\"with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        executor.map(process_commit, commit_information.iterrows())\"\"\"\n",
    "\n",
    "    for i, row in commit_information.iterrows():\n",
    "        if i>10:\n",
    "            break\n",
    "        process_commit((i, row))\n",
    "    \n",
    "    # Concatenate all collected results into a single DataFrame at the end\n",
    "    if results:\n",
    "        merged_df = pd.concat(results, ignore_index=True)\n",
    "        merged_df.to_csv(\"merged_df.csv\", index=False)\n",
    "        print(\"Results saved to 'merged_df.csv'\")\n",
    "    else:\n",
    "        print(\"No results to save.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 13:42:50,729 - INFO - Processing commit e296c698b83e320ff15c4ec1ca9258e188ff867c | 1 of 10146 commits | Number of merged commits: 0\n",
      "2025-02-03 13:42:50,729 - INFO - Processing commit e296c698b83e320ff15c4ec1ca9258e188ff867c | 1 of 10146 commits | Number of merged commits: 0\n",
      "2025-02-03 13:42:50,868 - INFO - Processing commit 9aa562f432ccfec587895b633c908eaa85f85f36 | 2 of 10146 commits | Number of merged commits: 4\n",
      "2025-02-03 13:42:50,868 - INFO - Processing commit 9aa562f432ccfec587895b633c908eaa85f85f36 | 2 of 10146 commits | Number of merged commits: 4\n",
      "2025-02-03 13:42:50,901 - INFO - Processing commit 83068da492974cd27ab0fcd85700af3e369d5490 | 3 of 10146 commits | Number of merged commits: 5\n",
      "2025-02-03 13:42:50,901 - INFO - Processing commit 83068da492974cd27ab0fcd85700af3e369d5490 | 3 of 10146 commits | Number of merged commits: 5\n",
      "2025-02-03 13:42:50,902 - INFO - Processing commit ed8f87a110ddcae69668aef0a4d8d4f4d292574d | 4 of 10146 commits | Number of merged commits: 5\n",
      "2025-02-03 13:42:50,902 - INFO - Processing commit ed8f87a110ddcae69668aef0a4d8d4f4d292574d | 4 of 10146 commits | Number of merged commits: 5\n",
      "2025-02-03 13:42:50,935 - INFO - Processing commit 9ca686b7a68e010d4d22d7ffb59d078d4c138109 | 5 of 10146 commits | Number of merged commits: 6\n",
      "2025-02-03 13:42:50,935 - INFO - Processing commit 9ca686b7a68e010d4d22d7ffb59d078d4c138109 | 5 of 10146 commits | Number of merged commits: 6\n",
      "2025-02-03 13:42:51,002 - INFO - Processing commit b7f7a176cccf501c44c6831bfd13fe82dd8ac85c | 6 of 10146 commits | Number of merged commits: 8\n",
      "2025-02-03 13:42:51,002 - INFO - Processing commit b7f7a176cccf501c44c6831bfd13fe82dd8ac85c | 6 of 10146 commits | Number of merged commits: 8\n",
      "2025-02-03 13:42:51,074 - INFO - Processing commit 403c571dd8a5442c73f8881aa1488387d69d6b09 | 7 of 10146 commits | Number of merged commits: 10\n",
      "2025-02-03 13:42:51,074 - INFO - Processing commit 403c571dd8a5442c73f8881aa1488387d69d6b09 | 7 of 10146 commits | Number of merged commits: 10\n",
      "2025-02-03 13:42:51,145 - INFO - Processing commit 29f0771bb06d0123c51cc41bf521610c6fdb4ab4 | 8 of 10146 commits | Number of merged commits: 12\n",
      "2025-02-03 13:42:51,145 - INFO - Processing commit 29f0771bb06d0123c51cc41bf521610c6fdb4ab4 | 8 of 10146 commits | Number of merged commits: 12\n",
      "2025-02-03 13:42:51,183 - INFO - Processing commit 541227d2ce8db9e7ab70f59d38982ee7a5ba6345 | 9 of 10146 commits | Number of merged commits: 13\n",
      "2025-02-03 13:42:51,183 - INFO - Processing commit 541227d2ce8db9e7ab70f59d38982ee7a5ba6345 | 9 of 10146 commits | Number of merged commits: 13\n",
      "2025-02-03 13:42:51,220 - INFO - Processing commit 3938bf3f604e8bed2a9a743ece707011247c75af | 10 of 10146 commits | Number of merged commits: 14\n",
      "2025-02-03 13:42:51,220 - INFO - Processing commit 3938bf3f604e8bed2a9a743ece707011247c75af | 10 of 10146 commits | Number of merged commits: 14\n",
      "2025-02-03 13:42:51,256 - INFO - Processing commit 469d85057fc415a95e34a1675f3e66ec992ec614 | 11 of 10146 commits | Number of merged commits: 15\n",
      "2025-02-03 13:42:51,256 - INFO - Processing commit 469d85057fc415a95e34a1675f3e66ec992ec614 | 11 of 10146 commits | Number of merged commits: 15\n",
      "2025-02-03 13:42:51,291 - INFO - Processing commit 21ccc7898120cc6f788ccb86d689e050f84d1e98 | 12 of 10146 commits | Number of merged commits: 16\n",
      "2025-02-03 13:42:51,291 - INFO - Processing commit 21ccc7898120cc6f788ccb86d689e050f84d1e98 | 12 of 10146 commits | Number of merged commits: 16\n",
      "2025-02-03 13:42:51,478 - INFO - Processing commit 3532616acc9b8428f51029e647743f6ee8e4e8b3 | 13 of 10146 commits | Number of merged commits: 22\n",
      "2025-02-03 13:42:51,478 - INFO - Processing commit 3532616acc9b8428f51029e647743f6ee8e4e8b3 | 13 of 10146 commits | Number of merged commits: 22\n",
      "2025-02-03 13:42:51,590 - INFO - Processing commit ce1f3b1c44f6b196d7bb278ebbb291b3dc78bd21 | 14 of 10146 commits | Number of merged commits: 25\n",
      "2025-02-03 13:42:51,590 - INFO - Processing commit ce1f3b1c44f6b196d7bb278ebbb291b3dc78bd21 | 14 of 10146 commits | Number of merged commits: 25\n",
      "2025-02-03 13:42:51,625 - INFO - Processing commit de328d05039fa1aa7c96ed2e9a78e6ba79ddb3d3 | 15 of 10146 commits | Number of merged commits: 26\n",
      "2025-02-03 13:42:51,625 - INFO - Processing commit de328d05039fa1aa7c96ed2e9a78e6ba79ddb3d3 | 15 of 10146 commits | Number of merged commits: 26\n",
      "2025-02-03 13:42:51,633 - INFO - Processing commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 16 of 10146 commits | Number of merged commits: 26\n",
      "2025-02-03 13:42:51,633 - INFO - Processing commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 16 of 10146 commits | Number of merged commits: 26\n",
      "2025-02-03 13:42:54,831 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 100 file of 2764 changed files | Number of merged commits: 126\n",
      "2025-02-03 13:42:54,831 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 100 file of 2764 changed files | Number of merged commits: 126\n",
      "2025-02-03 13:42:58,078 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 200 file of 2764 changed files | Number of merged commits: 226\n",
      "2025-02-03 13:42:58,078 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 200 file of 2764 changed files | Number of merged commits: 226\n",
      "2025-02-03 13:43:01,127 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 300 file of 2764 changed files | Number of merged commits: 326\n",
      "2025-02-03 13:43:01,127 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 300 file of 2764 changed files | Number of merged commits: 326\n",
      "2025-02-03 13:43:04,197 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 400 file of 2764 changed files | Number of merged commits: 426\n",
      "2025-02-03 13:43:04,197 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 400 file of 2764 changed files | Number of merged commits: 426\n",
      "2025-02-03 13:43:07,687 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 500 file of 2764 changed files | Number of merged commits: 526\n",
      "2025-02-03 13:43:07,687 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 500 file of 2764 changed files | Number of merged commits: 526\n",
      "2025-02-03 13:43:10,789 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 600 file of 2764 changed files | Number of merged commits: 626\n",
      "2025-02-03 13:43:10,789 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 600 file of 2764 changed files | Number of merged commits: 626\n",
      "2025-02-03 13:43:14,111 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 700 file of 2764 changed files | Number of merged commits: 726\n",
      "2025-02-03 13:43:14,111 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 700 file of 2764 changed files | Number of merged commits: 726\n",
      "2025-02-03 13:43:17,247 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 800 file of 2764 changed files | Number of merged commits: 826\n",
      "2025-02-03 13:43:17,247 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 800 file of 2764 changed files | Number of merged commits: 826\n",
      "2025-02-03 13:43:20,557 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 900 file of 2764 changed files | Number of merged commits: 926\n",
      "2025-02-03 13:43:20,557 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 900 file of 2764 changed files | Number of merged commits: 926\n",
      "2025-02-03 13:43:23,653 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1000 file of 2764 changed files | Number of merged commits: 1026\n",
      "2025-02-03 13:43:23,653 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1000 file of 2764 changed files | Number of merged commits: 1026\n",
      "2025-02-03 13:43:27,048 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1100 file of 2764 changed files | Number of merged commits: 1126\n",
      "2025-02-03 13:43:27,048 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1100 file of 2764 changed files | Number of merged commits: 1126\n",
      "2025-02-03 13:43:30,210 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1200 file of 2764 changed files | Number of merged commits: 1226\n",
      "2025-02-03 13:43:30,210 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1200 file of 2764 changed files | Number of merged commits: 1226\n",
      "2025-02-03 13:43:33,717 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1300 file of 2764 changed files | Number of merged commits: 1326\n",
      "2025-02-03 13:43:33,717 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1300 file of 2764 changed files | Number of merged commits: 1326\n",
      "2025-02-03 13:43:36,890 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1400 file of 2764 changed files | Number of merged commits: 1426\n",
      "2025-02-03 13:43:36,890 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1400 file of 2764 changed files | Number of merged commits: 1426\n",
      "2025-02-03 13:43:40,246 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1500 file of 2764 changed files | Number of merged commits: 1526\n",
      "2025-02-03 13:43:40,246 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1500 file of 2764 changed files | Number of merged commits: 1526\n",
      "2025-02-03 13:43:43,294 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1600 file of 2764 changed files | Number of merged commits: 1626\n",
      "2025-02-03 13:43:43,294 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1600 file of 2764 changed files | Number of merged commits: 1626\n",
      "2025-02-03 13:43:46,372 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1700 file of 2764 changed files | Number of merged commits: 1726\n",
      "2025-02-03 13:43:46,372 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1700 file of 2764 changed files | Number of merged commits: 1726\n",
      "2025-02-03 13:43:49,720 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1800 file of 2764 changed files | Number of merged commits: 1826\n",
      "2025-02-03 13:43:49,720 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1800 file of 2764 changed files | Number of merged commits: 1826\n",
      "2025-02-03 13:43:52,749 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1900 file of 2764 changed files | Number of merged commits: 1926\n",
      "2025-02-03 13:43:52,749 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 1900 file of 2764 changed files | Number of merged commits: 1926\n",
      "2025-02-03 13:43:56,515 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2000 file of 2764 changed files | Number of merged commits: 2026\n",
      "2025-02-03 13:43:56,515 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2000 file of 2764 changed files | Number of merged commits: 2026\n",
      "2025-02-03 13:44:00,585 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2100 file of 2764 changed files | Number of merged commits: 2126\n",
      "2025-02-03 13:44:00,585 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2100 file of 2764 changed files | Number of merged commits: 2126\n",
      "2025-02-03 13:44:04,161 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2200 file of 2764 changed files | Number of merged commits: 2226\n",
      "2025-02-03 13:44:04,161 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2200 file of 2764 changed files | Number of merged commits: 2226\n",
      "2025-02-03 13:44:07,397 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2300 file of 2764 changed files | Number of merged commits: 2326\n",
      "2025-02-03 13:44:07,397 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2300 file of 2764 changed files | Number of merged commits: 2326\n",
      "2025-02-03 13:44:10,772 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2400 file of 2764 changed files | Number of merged commits: 2426\n",
      "2025-02-03 13:44:10,772 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2400 file of 2764 changed files | Number of merged commits: 2426\n",
      "2025-02-03 13:44:13,871 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2500 file of 2764 changed files | Number of merged commits: 2526\n",
      "2025-02-03 13:44:13,871 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2500 file of 2764 changed files | Number of merged commits: 2526\n",
      "2025-02-03 13:44:17,537 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2600 file of 2764 changed files | Number of merged commits: 2626\n",
      "2025-02-03 13:44:17,537 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2600 file of 2764 changed files | Number of merged commits: 2626\n",
      "2025-02-03 13:44:20,626 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2700 file of 2764 changed files | Number of merged commits: 2726\n",
      "2025-02-03 13:44:20,626 - INFO - Merging commit 5a913ddbb89da00ecb0bccc9a7de100629d645ad | 2700 file of 2764 changed files | Number of merged commits: 2726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'merged_df.csv'\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_cbo</th>\n",
       "      <th>d_cboModified</th>\n",
       "      <th>d_fanin</th>\n",
       "      <th>d_fanout</th>\n",
       "      <th>d_wmc</th>\n",
       "      <th>d_dit</th>\n",
       "      <th>d_noc</th>\n",
       "      <th>d_rfc</th>\n",
       "      <th>d_lcom</th>\n",
       "      <th>d_lcom*</th>\n",
       "      <th>...</th>\n",
       "      <th>net_lines_changed</th>\n",
       "      <th>absolute_lines_changed</th>\n",
       "      <th>lines_per_file</th>\n",
       "      <th>author_experience</th>\n",
       "      <th>author_ownership</th>\n",
       "      <th>changed_file_count</th>\n",
       "      <th>entropy_bucket</th>\n",
       "      <th>num_files_changed</th>\n",
       "      <th>hash</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>22.7500</td>\n",
       "      <td>2818.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>e296c698b83e320ff15c4ec1ca9258e188ff867c</td>\n",
       "      <td>common/src/main/java/org/broadleafcommerce/com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>22.7500</td>\n",
       "      <td>2818.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>e296c698b83e320ff15c4ec1ca9258e188ff867c</td>\n",
       "      <td>common/src/main/java/org/broadleafcommerce/com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>22.7500</td>\n",
       "      <td>2818.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>e296c698b83e320ff15c4ec1ca9258e188ff867c</td>\n",
       "      <td>common/src/main/java/org/broadleafcommerce/com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>22.7500</td>\n",
       "      <td>2818.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>e296c698b83e320ff15c4ec1ca9258e188ff867c</td>\n",
       "      <td>core/broadleaf-framework/src/main/java/org/bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>9aa562f432ccfec587895b633c908eaa85f85f36</td>\n",
       "      <td>core/broadleaf-profile/src/main/java/org/broad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>...</td>\n",
       "      <td>9178.0</td>\n",
       "      <td>76858.0</td>\n",
       "      <td>27.5378</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2791</td>\n",
       "      <td>high</td>\n",
       "      <td>2791</td>\n",
       "      <td>5a913ddbb89da00ecb0bccc9a7de100629d645ad</td>\n",
       "      <td>core/broadleaf-profile/src/main/java/org/broad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>...</td>\n",
       "      <td>9178.0</td>\n",
       "      <td>76858.0</td>\n",
       "      <td>27.5378</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2791</td>\n",
       "      <td>high</td>\n",
       "      <td>2791</td>\n",
       "      <td>5a913ddbb89da00ecb0bccc9a7de100629d645ad</td>\n",
       "      <td>core/broadleaf-profile/src/main/java/org/broad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9178.0</td>\n",
       "      <td>76858.0</td>\n",
       "      <td>27.5378</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2791</td>\n",
       "      <td>high</td>\n",
       "      <td>2791</td>\n",
       "      <td>5a913ddbb89da00ecb0bccc9a7de100629d645ad</td>\n",
       "      <td>core/broadleaf-profile/src/main/java/org/broad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9178.0</td>\n",
       "      <td>76858.0</td>\n",
       "      <td>27.5378</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2791</td>\n",
       "      <td>high</td>\n",
       "      <td>2791</td>\n",
       "      <td>5a913ddbb89da00ecb0bccc9a7de100629d645ad</td>\n",
       "      <td>core/broadleaf-profile/src/main/java/org/broad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9178.0</td>\n",
       "      <td>76858.0</td>\n",
       "      <td>27.5378</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2791</td>\n",
       "      <td>high</td>\n",
       "      <td>2791</td>\n",
       "      <td>5a913ddbb89da00ecb0bccc9a7de100629d645ad</td>\n",
       "      <td>core/broadleaf-profile/src/main/java/org/broad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3309 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      d_cbo  d_cboModified  d_fanin  d_fanout  d_wmc  d_dit  d_noc  d_rfc  \\\n",
       "0         0              1        1         0      2      1      0      0   \n",
       "1         6              7        1         6      2      1      0      4   \n",
       "2         0              0        0         0      0      0      0      0   \n",
       "3         0              0        0         0      0      0      0      0   \n",
       "4         0              0        0         0      0      0      0      0   \n",
       "...     ...            ...      ...       ...    ...    ...    ...    ...   \n",
       "3304      0              0        0         0      0      0      0      0   \n",
       "3305      0              0        0         0      0      0      0      0   \n",
       "3306      0              0        0         0      0      0      0      0   \n",
       "3307      0              0        0         0      0      0      0      0   \n",
       "3308      0              0        0         0      0      0      0      0   \n",
       "\n",
       "      d_lcom   d_lcom*  ...  net_lines_changed  absolute_lines_changed  \\\n",
       "0          1  0.000000  ...               87.0                    91.0   \n",
       "1          1  0.500000  ...               87.0                    91.0   \n",
       "2          0  0.000000  ...               87.0                    91.0   \n",
       "3          0  0.000000  ...               87.0                    91.0   \n",
       "4          0  0.000000  ...                0.0                     2.0   \n",
       "...      ...       ...  ...                ...                     ...   \n",
       "3304       0  0.017857  ...             9178.0                 76858.0   \n",
       "3305       2  0.008889  ...             9178.0                 76858.0   \n",
       "3306       0  0.000000  ...             9178.0                 76858.0   \n",
       "3307       0  0.000000  ...             9178.0                 76858.0   \n",
       "3308       0  0.000000  ...             9178.0                 76858.0   \n",
       "\n",
       "      lines_per_file  author_experience  author_ownership  changed_file_count  \\\n",
       "0            22.7500             2818.5              53.0                   4   \n",
       "1            22.7500             2818.5              53.0                   4   \n",
       "2            22.7500             2818.5              53.0                   4   \n",
       "3            22.7500             2818.5              53.0                   4   \n",
       "4             2.0000               26.0              52.0                   1   \n",
       "...              ...                ...               ...                 ...   \n",
       "3304         27.5378             1416.0              52.0                2791   \n",
       "3305         27.5378             1416.0              52.0                2791   \n",
       "3306         27.5378             1416.0              52.0                2791   \n",
       "3307         27.5378             1416.0              52.0                2791   \n",
       "3308         27.5378             1416.0              52.0                2791   \n",
       "\n",
       "      entropy_bucket  num_files_changed  \\\n",
       "0                low                  4   \n",
       "1                low                  4   \n",
       "2                low                  4   \n",
       "3                low                  4   \n",
       "4                low                  1   \n",
       "...              ...                ...   \n",
       "3304            high               2791   \n",
       "3305            high               2791   \n",
       "3306            high               2791   \n",
       "3307            high               2791   \n",
       "3308            high               2791   \n",
       "\n",
       "                                          hash  \\\n",
       "0     e296c698b83e320ff15c4ec1ca9258e188ff867c   \n",
       "1     e296c698b83e320ff15c4ec1ca9258e188ff867c   \n",
       "2     e296c698b83e320ff15c4ec1ca9258e188ff867c   \n",
       "3     e296c698b83e320ff15c4ec1ca9258e188ff867c   \n",
       "4     9aa562f432ccfec587895b633c908eaa85f85f36   \n",
       "...                                        ...   \n",
       "3304  5a913ddbb89da00ecb0bccc9a7de100629d645ad   \n",
       "3305  5a913ddbb89da00ecb0bccc9a7de100629d645ad   \n",
       "3306  5a913ddbb89da00ecb0bccc9a7de100629d645ad   \n",
       "3307  5a913ddbb89da00ecb0bccc9a7de100629d645ad   \n",
       "3308  5a913ddbb89da00ecb0bccc9a7de100629d645ad   \n",
       "\n",
       "                                                   file  \n",
       "0     common/src/main/java/org/broadleafcommerce/com...  \n",
       "1     common/src/main/java/org/broadleafcommerce/com...  \n",
       "2     common/src/main/java/org/broadleafcommerce/com...  \n",
       "3     core/broadleaf-framework/src/main/java/org/bro...  \n",
       "4     core/broadleaf-profile/src/main/java/org/broad...  \n",
       "...                                                 ...  \n",
       "3304  core/broadleaf-profile/src/main/java/org/broad...  \n",
       "3305  core/broadleaf-profile/src/main/java/org/broad...  \n",
       "3306  core/broadleaf-profile/src/main/java/org/broad...  \n",
       "3307  core/broadleaf-profile/src/main/java/org/broad...  \n",
       "3308  core/broadleaf-profile/src/main/java/org/broad...  \n",
       "\n",
       "[3309 rows x 126 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the merged_df\n",
    "df = pd.read_csv(\"merged_df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f main main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f calculate_change_in_metrics main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
