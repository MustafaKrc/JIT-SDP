{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 22:41:33.443756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739907693.542106   78594 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739907693.567848   78594 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 22:41:33.834600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Positional Encoding Layer\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: Tensor of shape (batch_size, seq_len, d_model)\n",
    "        returns: inputs + positional encodings\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        d_model = tf.shape(inputs)[2]\n",
    "        # Compute the positional encodings\n",
    "        positions = tf.cast(tf.range(seq_len)[:, tf.newaxis], tf.float32)  # (seq_len, 1)\n",
    "        dims = tf.cast(tf.range(d_model)[tf.newaxis, :], tf.float32)       # (1, d_model)\n",
    "        angle_rates = 1 / tf.pow(10000.0, (2 * (dims // 2)) / tf.cast(d_model, tf.float32))\n",
    "        angle_rads = positions * angle_rates  # (seq_len, d_model)\n",
    "\n",
    "        # Apply sin to even indices and cos to odd indices\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = tf.expand_dims(pos_encoding, 0)  # (1, seq_len, d_model)\n",
    "        \n",
    "        return inputs + pos_encoding\n",
    "\n",
    "# Define a Transformer Encoder block\n",
    "def transformer_encoder_block(inputs, num_heads, ff_dim, dropout_rate):\n",
    "    # Multi-head self-attention\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "    \n",
    "    # Feed-forward network\n",
    "    ffn_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
    "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
    "    out2 = LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "    return out2\n",
    "\n",
    "# Build the Transformer-based model\n",
    "def create_transformer_model(input_shape, num_heads=4, ff_dim=128, dropout_rate=0.1, num_transformer_blocks=1):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "      input_shape: tuple, e.g. (window_size, num_features)\n",
    "      num_heads: Number of attention heads.\n",
    "      ff_dim: Dimension of the feed-forward network.\n",
    "      dropout_rate: Dropout rate.\n",
    "      num_transformer_blocks: Number of stacked Transformer blocks.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)  # (batch_size, seq_len, num_features)\n",
    "    \n",
    "    # Add positional encoding to maintain sequential information.\n",
    "    x = PositionalEncoding()(inputs)\n",
    "    \n",
    "    # Apply one or more Transformer encoder blocks.\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder_block(x, num_heads, ff_dim, dropout_rate)\n",
    "    \n",
    "    # Global average pooling over the sequence dimension.\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Output layer for binary classification.\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_date(x, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the input data into training and test sets by date.\n",
    "    The test set should contain the newest test_size proportion of the data.\n",
    "    \"\"\"\n",
    "    df = pd.concat([x, y], axis=1)\n",
    "    df = df.sort_values(by='author_date_unix_timestamp')\n",
    "    split_index = int((1 - test_size) * len(df))\n",
    "    x_train = df.iloc[:split_index, :-1]\n",
    "    y_train = df.iloc[:split_index, -1]\n",
    "    x_test = df.iloc[split_index:, :-1]\n",
    "    y_test = df.iloc[split_index:, -1]\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from mrmr import mrmr_classif\n",
    "\n",
    "def select_features(x, y, method=\"model\", estimator=None, threshold=\"median\", \n",
    "                    correlation_threshold=0.9, num_features=50):\n",
    "    \"\"\"\n",
    "    Select features using different methods.\n",
    "\n",
    "    Parameters:\n",
    "      - x: Training features (pandas DataFrame)\n",
    "      - y: Training labels (pandas Series)\n",
    "      - method: Which feature selection method to use.\n",
    "                Options are:\n",
    "                  \"model\" : Model-based feature selection using SelectFromModel.\n",
    "                  \"cbfs\"  : Correlation-based feature selection (CBFS).\n",
    "                  \"mrmr\"  : Minimum Redundancy Maximum Relevance (MRMR) using mrmr_selection.\n",
    "      - estimator: (For \"model\" method) An estimator to compute feature importances.\n",
    "                   If None, an XGBClassifier is used.\n",
    "      - threshold: (For \"model\" method) The threshold for feature importance in SelectFromModel.\n",
    "                   Default is \"median\".\n",
    "      - correlation_threshold: (For \"cbfs\" method) Threshold to drop highly correlated features.\n",
    "      - num_features: (For \"mrmr\" method) Number of features to select.\n",
    "      \n",
    "    Returns:\n",
    "      - A list of selected feature names.\n",
    "    \"\"\"\n",
    "    method = method.lower()\n",
    "    if method == \"model\":\n",
    "        if estimator is None:\n",
    "            estimator = XGBClassifier(tree_method=\"hist\", device=\"cuda\", random_state=42)\n",
    "        estimator.fit(x, y)\n",
    "        selector = SelectFromModel(estimator, threshold=threshold, prefit=True)\n",
    "        selected_features = list(x.columns[selector.get_support()])\n",
    "        return selected_features\n",
    "\n",
    "    elif method == \"cbfs\":\n",
    "        # Compute the absolute correlation matrix and remove one of any pair of highly correlated features.\n",
    "        corr_matrix = x.corr().abs()\n",
    "        # Use only the upper triangle of the correlation matrix.\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > correlation_threshold)]\n",
    "        selected_features = [col for col in x.columns if col not in to_drop]\n",
    "        return selected_features\n",
    "\n",
    "    elif method == \"mrmr\":\n",
    "        # Call mrmr_classif directly with the DataFrame (not x.values) so that it can access the column names.\n",
    "        selected_features = mrmr_classif(x, y, K=num_features)\n",
    "        return selected_features\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Method must be one of 'model', 'cbfs', or 'mrmr'\")\n",
    "    \n",
    "    # all columns in the dataset\n",
    "INFO_COLUMNS = [\n",
    "                \"type\", #\"linked\", \"fileschanged\",\n",
    "                \"ndev\", \"age\", \"exp\", \"rexp\", \"sexp\",\n",
    "                \"glm_probability\", \"classification\",\n",
    "                \"time_of_day\", \"day_of_week\", \"is_weekend\",\n",
    "                \"author_experience\", \"author_ownership\",\n",
    "                \"hash\",\"file\", \"author_date_unix_timestamp\"]\n",
    "\n",
    "Y_COLUMN = ['contains_bug']\n",
    "\n",
    "X_COLUMNS = [\"d_cbo\",\"d_cboModified\",\"d_fanin\",\n",
    "             \"d_fanout\",\"d_wmc\",\"d_dit\",\"d_noc\",\n",
    "             \"d_rfc\",\"d_lcom\",\"d_lcom*\",\"d_tcc\",\n",
    "             \"d_lcc\",\"d_totalMethodsQty\",\"d_staticMethodsQty\",\n",
    "             \"d_publicMethodsQty\",\"d_privateMethodsQty\",\"d_protectedMethodsQty\",\n",
    "             \"d_defaultMethodsQty\",\"d_visibleMethodsQty\",\"d_abstractMethodsQty\",\n",
    "             \"d_finalMethodsQty\",\"d_synchronizedMethodsQty\",\"d_totalFieldsQty\",\n",
    "             \"d_staticFieldsQty\",\"d_publicFieldsQty\",\"d_privateFieldsQty\",\n",
    "             \"d_protectedFieldsQty\",\"d_defaultFieldsQty\",\"d_finalFieldsQty\",\n",
    "             \"d_synchronizedFieldsQty\",\"d_nosi\",\"d_loc\",\"d_returnQty\",\"d_loopQty\",\n",
    "             \"d_comparisonsQty\",\"d_tryCatchQty\",\"d_parenthesizedExpsQty\",\"d_stringLiteralsQty\",\n",
    "             \"d_numbersQty\",\"d_assignmentsQty\",\"d_mathOperationsQty\",\"d_variablesQty\",\n",
    "             \"d_maxNestedBlocksQty\",\"d_anonymousClassesQty\",\"d_innerClassesQty\",\n",
    "             \"d_lambdasQty\",\n",
    "             #\"d_uniqueWordsQty\",\n",
    "             \"d_modifiers\",\n",
    "             #\"d_logStatementsQty\",\n",
    "             \"cbo\",\"cboModified\",\"fanin\",\"fanout\",\"wmc\",\"dit\",\"noc\",\"rfc\",\"lcom\",\"lcom*\",\n",
    "             \"tcc\",\"lcc\",\"totalMethodsQty\",\"staticMethodsQty\",\"publicMethodsQty\",\n",
    "             \"privateMethodsQty\",\"protectedMethodsQty\",\"defaultMethodsQty\",\n",
    "             \"visibleMethodsQty\",\"abstractMethodsQty\",\"finalMethodsQty\",\n",
    "             \"synchronizedMethodsQty\",\"totalFieldsQty\",\"staticFieldsQty\",\n",
    "             \"publicFieldsQty\",\"privateFieldsQty\",\"protectedFieldsQty\",\n",
    "             \"defaultFieldsQty\",\"finalFieldsQty\",\"synchronizedFieldsQty\",\n",
    "             \"nosi\",\"loc\",\"returnQty\",\"loopQty\",\"comparisonsQty\",\n",
    "             \"tryCatchQty\",\"parenthesizedExpsQty\",\"stringLiteralsQty\",\n",
    "             \"numbersQty\",\"assignmentsQty\",\"mathOperationsQty\",\n",
    "             \"variablesQty\",\"maxNestedBlocksQty\",\"anonymousClassesQty\",\n",
    "             \"innerClassesQty\",\"lambdasQty\",\n",
    "             #\"uniqueWordsQty\", # Number of unique words in the source code\n",
    "             \"modifiers\",\n",
    "             #\"logStatementsQty\", # Number of log statements in the source code\n",
    "             #\"fix\",\n",
    "             \"entrophy\",\n",
    "             \"la\",\"ld\",\n",
    "             #\"net_lines_changed\",\"absolute_lines_changed\",\n",
    "             \"lines_per_file\",\n",
    "             \"changed_file_count\",\n",
    "             #\"entropy_bucket\",\n",
    "             ]\n",
    "\n",
    "DATASETS = [\"merged_datasets/new/broadleaf_merged_df.csv\",\n",
    "            \"merged_datasets/new/camel_merged_df.csv\",\n",
    "            \"merged_datasets/new/dubbo_merged_df.csv\",\n",
    "            \"merged_datasets/new/elasticsearch_merged_df.csv\",\n",
    "            \"merged_datasets/new/guava_merged_df.csv\",\n",
    "            \"merged_datasets/new/jdk_merged_df.csv\",\n",
    "            \"merged_datasets/new/jgroups_merged_df.csv\",\n",
    "            \"merged_datasets/new/kafka_merged_df.csv\",\n",
    "            \"merged_datasets/new/spark_merged_df.csv\",\n",
    "            \"merged_datasets/new/spring-boot_merged_df.csv\",\n",
    "            \"merged_datasets/new/spring-framework_merged_df.csv\",\n",
    "            \"merged_datasets/new/tomcat_merged_df.csv\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_window(X, y, window_size):\n",
    "    \"\"\"\n",
    "    Transform the data into sequences using a sliding window approach.\n",
    "    \n",
    "    Parameters:\n",
    "      X (np.array): Array of features (already scaled).\n",
    "      y (np.array): Array of target values.\n",
    "      window_size (int): Number of consecutive rows in each window.\n",
    "    \n",
    "    Returns:\n",
    "      X_seq (np.array): Array of sequences with shape (samples, window_size, features).\n",
    "      y_seq (np.array): Array of labels corresponding to each sequence.\n",
    "                         Here, the label for a window is the label of the last row.\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - window_size + 1):\n",
    "        X_seq.append(X[i: i+window_size])\n",
    "        y_seq.append(y[i+window_size-1])\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['d_cbo', 'd_cboModified', 'd_fanin', 'd_fanout', 'd_wmc', 'd_dit', 'd_noc', 'd_rfc', 'd_lcom', 'd_lcom*', 'd_tcc', 'd_lcc', 'd_totalMethodsQty', 'd_staticMethodsQty', 'd_publicMethodsQty', 'd_privateMethodsQty', 'd_protectedMethodsQty', 'd_defaultMethodsQty', 'd_visibleMethodsQty', 'd_abstractMethodsQty', 'd_finalMethodsQty', 'd_synchronizedMethodsQty', 'd_totalFieldsQty', 'd_staticFieldsQty', 'd_publicFieldsQty', 'd_privateFieldsQty', 'd_protectedFieldsQty', 'd_defaultFieldsQty', 'd_finalFieldsQty', 'd_synchronizedFieldsQty', 'd_nosi', 'd_loc', 'd_returnQty', 'd_loopQty', 'd_comparisonsQty', 'd_tryCatchQty', 'd_parenthesizedExpsQty', 'd_stringLiteralsQty', 'd_numbersQty', 'd_assignmentsQty', 'd_mathOperationsQty', 'd_variablesQty', 'd_maxNestedBlocksQty', 'd_anonymousClassesQty', 'd_innerClassesQty', 'd_lambdasQty', 'd_modifiers', 'cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*', 'tcc', 'lcc', 'totalMethodsQty', 'staticMethodsQty', 'publicMethodsQty', 'privateMethodsQty', 'protectedMethodsQty', 'defaultMethodsQty', 'visibleMethodsQty', 'abstractMethodsQty', 'finalMethodsQty', 'synchronizedMethodsQty', 'totalFieldsQty', 'staticFieldsQty', 'publicFieldsQty', 'privateFieldsQty', 'protectedFieldsQty', 'defaultFieldsQty', 'finalFieldsQty', 'synchronizedFieldsQty', 'nosi', 'loc', 'returnQty', 'loopQty', 'comparisonsQty', 'tryCatchQty', 'parenthesizedExpsQty', 'stringLiteralsQty', 'numbersQty', 'assignmentsQty', 'mathOperationsQty', 'variablesQty', 'maxNestedBlocksQty', 'anonymousClassesQty', 'innerClassesQty', 'lambdasQty', 'modifiers', 'entrophy', 'la', 'ld', 'lines_per_file', 'changed_file_count']\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset_file = DATASETS[0]\n",
    "df = pd.read_csv(dataset_file)\n",
    "\n",
    "df = df.fillna(-1)\n",
    "\n",
    "# Extract features and target. Make sure these columns exist in the CSV.\n",
    "X = df[X_COLUMNS + INFO_COLUMNS]\n",
    "y = df[Y_COLUMN]\n",
    "\n",
    "# Split the dataset by date using the provided function\n",
    "x_train, x_test, y_train, y_test = train_test_split_by_date(X, y, test_size=0.2)\n",
    "\n",
    "# Perform feature selection on the training set using only X_COLUMNS\n",
    "selected_features = select_features(x_train[X_COLUMNS], y_train,\n",
    "                                            method=\"cbfs\", correlation_threshold=1)\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(len(selected_features))\n",
    "\n",
    "# Scale the features (LSTM models often perform better with scaled inputs)\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train[selected_features])\n",
    "x_test_scaled = scaler.transform(x_test[selected_features])\n",
    "\n",
    "# Define the sliding window size (N)\n",
    "window_size = 25  \n",
    "\n",
    "# Create sliding windows for both the training and test sets.\n",
    "# The label for each window is taken as the label of the last row in that window.\n",
    "x_train_seq, y_train_seq = create_sliding_window(x_train_scaled, y_train.to_numpy(), window_size)\n",
    "x_test_seq, y_test_seq = create_sliding_window(x_test_scaled, y_test.to_numpy(), window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.7973117901473329), 1: np.float64(1.3408680997013689)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Get unique classes and compute weights\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", \n",
    "                                     classes=np.unique(y_train_seq), \n",
    "                                     y=y_train_seq)\n",
    "\n",
    "# Convert to a dictionary format required by Keras\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "# Convert to a dictionary format required by Keras\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739907704.340472   78594 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2248 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encoding │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncodin…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">158,103</span> │ positional_encod… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ positional_encod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_encod… │\n",
       "│                     │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,800</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,771</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">158,103</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,800</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,771</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encoding │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mPositionalEncodin…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │    \u001b[38;5;34m158,103\u001b[0m │ positional_encod… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ positional_encod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ positional_encod… │\n",
       "│                     │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │        \u001b[38;5;34m198\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m12,800\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │     \u001b[38;5;34m12,771\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │        \u001b[38;5;34m198\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │    \u001b[38;5;34m158,103\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │        \u001b[38;5;34m198\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m12,800\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │     \u001b[38;5;34m12,771\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m99\u001b[0m)    │        \u001b[38;5;34m198\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m100\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">368,240</span> (1.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m368,240\u001b[0m (1.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">368,240</span> (1.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m368,240\u001b[0m (1.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 22:41:47.774097: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 897920100 exceeds 10% of free system memory.\n",
      "2025-02-18 22:41:49.111412: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 897920100 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739907713.740275   78820 service.cc:148] XLA service 0x7f8da4008040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739907713.740910   78820 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-02-18 22:41:53.892739: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1739907714.547561   78820 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   3/2835\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 46ms/step - accuracy: 0.5052 - loss: 1.2348  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 22:41:59.966152: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'input_add_multiply_reduce_fusion', 52 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1739907720.006190   78820 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7131 - loss: 0.5928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 22:42:27.307023: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 224304300 exceeds 10% of free system memory.\n",
      "2025-02-18 22:42:27.470533: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 224304300 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 12ms/step - accuracy: 0.7132 - loss: 0.5928 - val_accuracy: 0.7761 - val_loss: 0.6464\n",
      "Epoch 2/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7692 - loss: 0.5201 - val_accuracy: 0.7606 - val_loss: 0.6786\n",
      "Epoch 3/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7705 - loss: 0.5052 - val_accuracy: 0.7136 - val_loss: 0.6158\n",
      "Epoch 4/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.5362 - val_accuracy: 0.7653 - val_loss: 0.5950\n",
      "Epoch 5/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7772 - loss: 0.4941 - val_accuracy: 0.7596 - val_loss: 0.5622\n",
      "Epoch 6/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - accuracy: 0.7775 - loss: 0.4903 - val_accuracy: 0.7645 - val_loss: 0.6242\n",
      "Epoch 7/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - accuracy: 0.7759 - loss: 0.4936 - val_accuracy: 0.7752 - val_loss: 0.6228\n",
      "Epoch 8/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7702 - loss: 0.5190 - val_accuracy: 0.7627 - val_loss: 0.7052\n",
      "Epoch 9/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - accuracy: 0.7719 - loss: 0.5204 - val_accuracy: 0.7547 - val_loss: 0.7103\n",
      "Epoch 10/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.7759 - loss: 0.4957 - val_accuracy: 0.7774 - val_loss: 0.4777\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assuming x_train_seq and x_test_seq are your sliding window sequences with shape (samples, window_size, num_features)\n",
    "input_shape = (x_train_seq.shape[1], x_train_seq.shape[2])\n",
    "transformer_model = create_transformer_model(input_shape, num_heads=4, ff_dim=128, dropout_rate=0.1, num_transformer_blocks=2)\n",
    "\n",
    "# Print the model summary\n",
    "transformer_model.summary()\n",
    "\n",
    "# Train the model (using the same training and validation sets as before)\n",
    "history = transformer_model.fit(x_train_seq, y_train_seq,\n",
    "                                epochs=10,\n",
    "                                batch_size=32,\n",
    "                                validation_data=(x_test_seq, y_test_seq),\n",
    "                                class_weight=class_weight_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 11/709\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1292  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 22:46:27.322805: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 224304300 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8532 - loss: 0.3408\n",
      "Test loss: 0.4777, Test accuracy: 0.7774\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_metrics = transformer_model.evaluate(x_test_seq, y_test_seq)\n",
    "print(f'Test loss: {test_metrics[0]:.4f}, Test accuracy: {test_metrics[1]:.4f}')\n",
    "\n",
    "# Make predictions and generate a classification report (as before)\n",
    "y_pred_probs = transformer_model.predict(x_test_seq)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.23      0.35      5949\n",
      "        True       0.78      0.97      0.87     16708\n",
      "\n",
      "    accuracy                           0.78     22657\n",
      "   macro avg       0.76      0.60      0.61     22657\n",
      "weighted avg       0.77      0.78      0.73     22657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test_seq, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test_seq, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
